{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:54:48.303019Z",
     "start_time": "2023-11-19T15:54:46.280281Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 1. Data collection\n",
    "\n",
    "## 1.1. Get the list of master's degree courses\n",
    "We created a file named 'urls.txt' that contains all the urls associated with the url of each master page.\n",
    "for reaching such purpose, we iterate over all 400 pages and took the link for every 15 urls of each page.\n",
    "we stored all urls in 'urls.txt' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:31:44.436742Z",
     "start_time": "2023-11-18T16:29:57.119032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"urls.txt\" file is generated!\n"
     ]
    }
   ],
   "source": [
    "f = open(\"urls.txt\",\"w\") # First we create a txt file where we can write the URLs  #  w means writing mode\n",
    "for i in range(1, 401): #from first page to page 400\n",
    "    url = f\"https://www.findamasters.com/masters-degrees/msc-degrees/?PG={i}\" #pages can be scrolled by changing the number after PG\n",
    "    result = requests.get(url) # as we have done in class\n",
    "    soup = BeautifulSoup(result.text, 'html.parser') # to get the html of each page\n",
    "\n",
    "    for link in soup.find_all(class_ = re.compile('courseLink')): #as in class to get each tag of the page which belongs to class courseLink\n",
    "        c = (link.get(\"href\"))  # url of each page in the i-th page\n",
    "        f.write(\"https://www.findamasters.com/\"+c) #writing the rows\n",
    "        f.write(\"\\n\")\n",
    "f.close()\n",
    "print('The \"urls.txt\" file is generated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl master's degree pages\n",
    "\n",
    "We wrote a function named 'download_url'.\n",
    "Since the FindMaster website blocks us for 70 seconds for every (20 to 22) requests we send, we use 'time.sleep(70)' to wait and then resend the http get request. \n",
    "we also omit to download the http files that their directory are already existed.\n",
    "\n",
    "for sending http get requests asynchronously, we can use async and await methods and take the advantage of using \"aiohttp\" library. the other way is to use ThreadPoolExecutor function executer. \n",
    "It means that we store the executer command in a variable named 'future_to_url' that we are able to call in the future.\n",
    "The ThreadPoolExecutor is a built-in Python module that provides managing a pool of worker threads. It allows us to submit tasks to the pool, which are then executed by one of the worker threads in the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All HTML files are stored in the HTML_folders directory.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Function to download and save HTML for a given URL\n",
    "def download_url(url, folder_path, page_number):\n",
    "    # Create a folder for each page if it doesn't exist\n",
    "    page_folder = os.path.join(folder_path, f\"page_{page_number}\")\n",
    "    if os.path.exists(page_folder):\n",
    "        # uncomment the below code to see which pages are skiped, cause they have already been downloaded.\n",
    "        # print(f\"Skipping Page: {page_number} - Folder already exists.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url) # Send a GET request to the URL\n",
    "        response.raise_for_status()  # Raise an exception for bad responses \n",
    "\n",
    "        # Create a folder for each page if it doesn't exist\n",
    "        os.makedirs(page_folder, exist_ok=True)\n",
    "\n",
    "        # Save the HTML content to a file\n",
    "        file_path = os.path.join(page_folder, f\"html_{page_number}.html\")\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"Downloaded page {page_number}: {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download page {page_number}: {url}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Retrying in 70 seconds...\")\n",
    "        time.sleep(70)  # Wait for 10 seconds before retrying\n",
    "        download_url(url, folder_path, page_number)  # Retry the download\n",
    "\n",
    "# Read all URLs one by one\n",
    "with open('urls.txt', 'r') as urls_file:\n",
    "    urls = urls_file.read().splitlines()\n",
    "\n",
    "output_folder = 'HTML_folders' # Store all HTML files into this directory.\n",
    "\n",
    "# We can use ThreadPoolExecutor for sending http requests asynchronously. \n",
    "# However, Since the FindMaster website blocks us for 70 seconds for every (20 to 22) requests we send, \n",
    "# the max_workers in below code assigned to number 1. So it sends requests synchronously.\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    # Enumerate through each URL and submit download tasks to the executor\n",
    "    future_to_url = {executor.submit(download_url, url, output_folder, page_number): url for page_number, url in enumerate(urls, start=1)}\n",
    "\n",
    "print(\"All HTML files are stored in the HTML_folders directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages\n",
    "Here we create a '.tsv' file including the following columns for each of the HTML files.\n",
    "\n",
    "1. Course Name (to save as ```courseName```): string;\n",
    "2. University (to save as ```universityName```): string;\n",
    "3. Faculty (to save as ```facultyName```): string\n",
    "4. Full or Part Time (to save as ```isItFullTime```): string;\n",
    "5. Short Description (to save as ```description```): string;\n",
    "6. Start Date (to save as ```startDate```): string;\n",
    "7. Fees (to save as ```fees```): string;\n",
    "8. Modality (to save as ```modality```):string;\n",
    "9. Duration (to save as ```duration```):string;\n",
    "10. City (to save as ```city```): string;\n",
    "11. Country (to save as ```country```): string;\n",
    "12. Presence or online modality (to save as ```administration```): string;\n",
    "13. Link to the page (to save as ```url```): string.\n",
    "\n",
    "Then, we merge all those files together to generate our final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All HTML files have been read and all .tsv files have been generated.\n"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "# '/Users/armanfeili/Arman/Sapienza Courses/ADM/Homeworks/HW3/phase-2/ADM-HW3/HTML_folders'\n",
    "\n",
    "for i in range(1,6001):\n",
    "    # os.chdir(r'C:\\Users\\susan\\Documents\\DS\\ADM\\HW3\\ADM-HW3\\HTML_folders\\page_'+str(i)) #change directories\n",
    "    os.chdir(r'/Users/armanfeili/Arman/Sapienza Courses/ADM/Homeworks/HW3/phase-3/ADM-HW3/HTML_folders/page_'+str(i)) #change directories\n",
    "    \n",
    "    for filename in os.listdir(os.getcwd()): # get all the files in a folder\n",
    "        if filename.endswith(\".tsv\"): continue # tsv file is already generated.\n",
    "        elif filename.endswith(\".html\"): # if file extension is .html\n",
    "            with open(os.path.join(os.getcwd(), filename), 'r',encoding='utf-8') as f: # open each file into a folder\n",
    "                soup = BeautifulSoup(f,'html.parser') # get the html file by each file \n",
    "                out=[] # initialize a list where we append all the informations parsed from each html file\n",
    "\n",
    "                # 1  Course Name\n",
    "                courseName = soup.find_all(class_=re.compile(\"course-header__course-title\"))\n",
    "                out.append(courseName[0].text.strip() if courseName else \"\") #text.strip to eliminate strange simbols for the space\n",
    "                # 2  University\n",
    "                universityName = soup.find_all(class_=re.compile(\"course-header__institution\"))\n",
    "                out.append(universityName[0].text if universityName else \"\")\n",
    "                # 3  Faculty\n",
    "                facultyName = soup.find_all(class_=re.compile(\"course-header__department\"))\n",
    "                out.append(facultyName[0].text if facultyName else \"\")\n",
    "                # 4  Full or Part Time\n",
    "                isItFullTime = soup.find_all(class_=re.compile(\"concealLink\"))\n",
    "                out.append(isItFullTime[0].text if isItFullTime else \"\")\n",
    "                # 5  Short Description\n",
    "                description = soup.find_all(class_=re.compile(\"course-sections__content\"))\n",
    "                out.append(description[0].text.replace('\\n', '') if description else \"\")\n",
    "                # 6  Start Date\n",
    "                startDate = soup.find_all(class_=re.compile(\"key-info__start-date\"))\n",
    "                out.append(startDate[0].text if startDate else \"\")\n",
    "                # 7  Fees \n",
    "                fees_elements = soup.find_all(class_=re.compile(\"course-sections__fees\")) # taking the fee\n",
    "                fees_text = fees_elements[0].text.replace('\\n', '') if fees_elements else \"\" \n",
    "                cleaned_fees = re.sub(r'Fees', '', fees_text)  # To not \"Fees\" at the beginning \n",
    "                out.append(cleaned_fees.strip() if cleaned_fees else \"\")\n",
    "                # 8  Modality\n",
    "                modality = soup.find_all(class_=re.compile(\"key-info__qualification\"))\n",
    "                out.append(modality[0].text if modality else \"\")\n",
    "                # 9  Duration\n",
    "                duration = soup.find_all(class_=re.compile(\"key-info__duration\"))\n",
    "                out.append(duration[0].text if duration else \"\")\n",
    "                # 10  City\n",
    "                city = soup.find_all(class_=re.compile(\"course-data__city\"))\n",
    "                out.append(city[0].text if city else \"\")\n",
    "                # 11  Country\n",
    "                country = soup.find_all(class_=re.compile(\"course-data__country\"))\n",
    "                out.append(country[0].text if country else \"\")\n",
    "                # 12  Presence or online modality\n",
    "                # We have seen that some courses has both online or oncampus modality, one of them is \"Master of Business Administration\"\n",
    "                on_campus_elements = soup.find_all(class_=re.compile(\"course-data__on-campus\"))\n",
    "                online_elements = soup.find_all(class_=re.compile(\"course-data__online\"))\n",
    "                if on_campus_elements and online_elements:\n",
    "                    out.append(\"both\")\n",
    "                else:\n",
    "                    out.append(on_campus_elements[0].text if on_campus_elements else online_elements[0].text if online_elements else \"Nan\")\n",
    "                # 13  Link to the page\n",
    "                out.append(soup.find('link', {'rel': 'canonical'}).get('href') if soup.find('link', {'rel': 'canonical'}) else \"Nan\")\n",
    "                f.close()\n",
    "                \n",
    "                # Creating file .tsv\n",
    "                l = ['courseName','universityName','facultyName','isItFullTime','description','startDate','fees','modality','duration',\n",
    "                    'city','country','administration','url']\n",
    "                with open(filename+'.tsv','w',encoding='utf-8') as tsv:\n",
    "                    tsv_output = csv.writer(tsv, delimiter='\\t')\n",
    "                    tsv_output.writerow(l)\n",
    "                    tsv_output.writerow(out)\n",
    "    os.chdir('..')  \n",
    "\n",
    "print(\"All HTML files have been read and all .tsv files have been generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.tsv file has been generated as the main dataset.\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "# to merge all the .tsv files\n",
    "for i in range(1,6001):\n",
    "    # os.chdir(r'./HTML_folders/page_'+str(i)) #change directories\n",
    "    os.chdir(r'/Users/armanfeili/Arman/Sapienza Courses/ADM/Homeworks/HW3/phase-3/ADM-HW3/HTML_folders/page_'+str(i)) #change directories\n",
    "    for filename in os.listdir(os.getcwd()):\n",
    "        if filename.endswith(\".tsv\"):\n",
    "            a = pd.read_csv(filename,sep='\\t')\n",
    "            data.append(a)\n",
    "    os.chdir('..')\n",
    "data=pd.concat(data,ignore_index=True)   \n",
    "data.to_csv('../dataset.tsv',sep='\\t',index=False) # Saving the big one\n",
    "print(\"dataset.tsv file has been generated as the main dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Design for Virtual Environments - MSc</td>\n",
       "      <td>Glasgow Caledonian University</td>\n",
       "      <td>School of Engineering and Built Environment</td>\n",
       "      <td>Full time</td>\n",
       "      <td>3D visualisation and animation play a role in ...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full-time</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting and Finance - MSc</td>\n",
       "      <td>University of Leeds</td>\n",
       "      <td>Leeds University Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Businesses and governments rely on sound finan...</td>\n",
       "      <td>September</td>\n",
       "      <td>UK: £18,000 (Total) International: £34,750 (To...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accounting, Accountability &amp; Financial Managem...</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>King’s Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Our Accounting, Accountability &amp; Financial Man...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year FT</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accounting, Financial Management and Digital B...</td>\n",
       "      <td>University of Reading</td>\n",
       "      <td>Henley Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Embark on a professional accounting career wit...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time</td>\n",
       "      <td>Reading</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addictions MSc</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>Institute of Psychiatry, Psychology and Neuros...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Join us for an online session for prospective ...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>One year FT</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          courseName  \\\n",
       "0           3D Design for Virtual Environments - MSc   \n",
       "1                       Accounting and Finance - MSc   \n",
       "2  Accounting, Accountability & Financial Managem...   \n",
       "3  Accounting, Financial Management and Digital B...   \n",
       "4                                     Addictions MSc   \n",
       "\n",
       "                  universityName  \\\n",
       "0  Glasgow Caledonian University   \n",
       "1            University of Leeds   \n",
       "2          King’s College London   \n",
       "3          University of Reading   \n",
       "4          King’s College London   \n",
       "\n",
       "                                         facultyName isItFullTime  \\\n",
       "0        School of Engineering and Built Environment    Full time   \n",
       "1                   Leeds University Business School    Full time   \n",
       "2                             King’s Business School    Full time   \n",
       "3                             Henley Business School    Full time   \n",
       "4  Institute of Psychiatry, Psychology and Neuros...    Full time   \n",
       "\n",
       "                                         description  startDate  \\\n",
       "0  3D visualisation and animation play a role in ...  September   \n",
       "1  Businesses and governments rely on sound finan...  September   \n",
       "2  Our Accounting, Accountability & Financial Man...  September   \n",
       "3  Embark on a professional accounting career wit...  September   \n",
       "4  Join us for an online session for prospective ...  September   \n",
       "\n",
       "                                                fees modality  \\\n",
       "0  Please see the university website for further ...      MSc   \n",
       "1  UK: £18,000 (Total) International: £34,750 (To...      MSc   \n",
       "2  Please see the university website for further ...      MSc   \n",
       "3  Please see the university website for further ...      MSc   \n",
       "4  Please see the university website for further ...      MSc   \n",
       "\n",
       "           duration     city         country administration  \\\n",
       "0  1 year full-time  Glasgow  United Kingdom      On Campus   \n",
       "1  1 year full time    Leeds  United Kingdom      On Campus   \n",
       "2         1 year FT   London  United Kingdom      On Campus   \n",
       "3  1 year full time  Reading  United Kingdom      On Campus   \n",
       "4       One year FT   London  United Kingdom      On Campus   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.findamasters.com/masters-degrees/c...  \n",
       "1  https://www.findamasters.com/masters-degrees/c...  \n",
       "2  https://www.findamasters.com/masters-degrees/c...  \n",
       "3  https://www.findamasters.com/masters-degrees/c...  \n",
       "4  https://www.findamasters.com/masters-degrees/c...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An illustration to the dataset:\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:47:23.231905Z",
     "start_time": "2023-11-19T15:47:23.089236Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset we are going to work with\n",
    "data = pd.read_table(r\"dataset.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2.0 Preprocessing\n",
    "\n",
    "### 2.0.0)  Preprocessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:47:24.358121Z",
     "start_time": "2023-11-19T15:47:24.335086Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This function takes a text, removes special cases, punctuations and stop-words then\n",
    "# it applies stemming and finally returns the preprocessed words separated by commas.\n",
    "# TODO maybe they want to apply this to the whole data, not just description\n",
    "def preprocess_description(description_text):\n",
    "\n",
    "    # Handle the cases of float type (there are 24)\n",
    "    if type(description_text) != str:\n",
    "        return \"\"\n",
    "\n",
    "    # Remove all special chars and punctuations\n",
    "    description_text = re.sub(\"[^a-z A-Z ]+\",\"\", description_text)\n",
    "\n",
    "    # Convert everything in lowercase\n",
    "    description_text = description_text.lower()\n",
    "\n",
    "    # Remove stopwords using nltk package\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = nltk.word_tokenize(description_text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Apply stemming using ntlk package\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Separate words with commas\n",
    "    words = ','.join(words)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:47:42.961286Z",
     "start_time": "2023-11-19T15:47:30.907500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create and fill new column where the preprocessed descriptions wil be stored:\n",
    "data[\"clean_description\"] = data[\"description\"].apply(preprocess_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:47:47.186502Z",
     "start_time": "2023-11-19T15:47:47.103480Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>clean_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D visualisation and animation play a role in ...</td>\n",
       "      <td>visualis,anim,play,role,mani,area,popular,medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Businesses and governments rely on sound finan...</td>\n",
       "      <td>busi,govern,reli,sound,financi,knowledg,underp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our Accounting, Accountability &amp; Financial Man...</td>\n",
       "      <td>account,account,financi,manag,msc,cours,provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embark on a professional accounting career wit...</td>\n",
       "      <td>embark,profession,account,career,academ,ground...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Join us for an online session for prospective ...</td>\n",
       "      <td>join,us,onlin,session,prospect,student,find,ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Advanced Chemical Engineering MSc at Leeds...</td>\n",
       "      <td>advanc,chemic,engin,msc,leed,build,core,founda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Programme overviewThe Advanced Master in Finan...</td>\n",
       "      <td>programm,overviewth,advanc,master,financi,mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Programme overviewThe Advanced Master in Innov...</td>\n",
       "      <td>programm,overviewth,advanc,master,innov,strate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Progress your career as a physiotherapist with...</td>\n",
       "      <td>progress,career,physiotherapist,within,nh,priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Goal of the pro­grammeWould you like to be inv...</td>\n",
       "      <td>goal,programmewould,like,involv,find,solut,fut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  3D visualisation and animation play a role in ...   \n",
       "1  Businesses and governments rely on sound finan...   \n",
       "2  Our Accounting, Accountability & Financial Man...   \n",
       "3  Embark on a professional accounting career wit...   \n",
       "4  Join us for an online session for prospective ...   \n",
       "5  The Advanced Chemical Engineering MSc at Leeds...   \n",
       "6  Programme overviewThe Advanced Master in Finan...   \n",
       "7  Programme overviewThe Advanced Master in Innov...   \n",
       "8  Progress your career as a physiotherapist with...   \n",
       "9  Goal of the pro­grammeWould you like to be inv...   \n",
       "\n",
       "                                   clean_description  \n",
       "0  visualis,anim,play,role,mani,area,popular,medi...  \n",
       "1  busi,govern,reli,sound,financi,knowledg,underp...  \n",
       "2  account,account,financi,manag,msc,cours,provid...  \n",
       "3  embark,profession,account,career,academ,ground...  \n",
       "4  join,us,onlin,session,prospect,student,find,ms...  \n",
       "5  advanc,chemic,engin,msc,leed,build,core,founda...  \n",
       "6  programm,overviewth,advanc,master,financi,mark...  \n",
       "7  programm,overviewth,advanc,master,innov,strate...  \n",
       "8  progress,career,physiotherapist,within,nh,priv...  \n",
       "9  goal,programmewould,like,involv,find,solut,fut...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show different fields\n",
    "data[[\"description\", \"clean_description\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1) Preprocessing the fees column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:16.335138Z",
     "start_time": "2023-11-19T15:53:16.321688Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This function was provided by ChatGPT.\n",
    "# It downloads the latest exchange rates (wrt United States Dollars) from openexchangerates.org.\n",
    "# It returns a dictionary of the form {exchange_code : exchange_rate}\n",
    "def get_latest_exchange_rates(app_id):\n",
    "\n",
    "    base_url = \"https://openexchangerates.org/api/latest.json\"\n",
    "    params = {\"app_id\": app_id}\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"rates\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch exchange rates. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Dictionary provided by ChatGPT, I changed some symbols that were not present.\n",
    "# It will be used to convert a currency symbol into currency code.\n",
    "\n",
    "currency_symbol_to_code = {\n",
    "    '$': 'USD',  # United States Dollar\n",
    "    '€': 'EUR',  # Euro\n",
    "    \"EURO\": \"EUR\", # Euro\n",
    "    '¥': 'JPY',  # Japanese Yen\n",
    "    '£': 'GBP',  # British Pound Sterling\n",
    "    'A$': 'AUD',  # Australian Dollar\n",
    "    'C$': 'CAD',  # Canadian Dollar\n",
    "    'CHF': 'CHF',  # Swiss Franc\n",
    "    'KR': 'SEK',  # Swedish Krona\n",
    "    'NZ$': 'NZD',  # New Zealand Dollar\n",
    "    # Add more symbols and codes as needed\n",
    "}\n",
    "\n",
    "# This function handles the preprocessing of the \"fees\" field\n",
    "def preprocess_fees(fees_text):\n",
    "\n",
    "    # Handles the case of \"nan\"\n",
    "    if type(fees_text) != str:\n",
    "        return None\n",
    "\n",
    "    # Preallocate all the fees found in text\n",
    "    total_fees = []\n",
    "\n",
    "    # Symbols we are looking for\n",
    "    symbols = \"GBP|USD|ISK|£|\\$|₹|¥|₪|₽|₩|₦|₴|﷼|€|Euro\"\n",
    "\n",
    "    # Match the (symbol, number) case\n",
    "    left_symbol_matches = re.findall(fr'(?:{symbols})+\\s*[0-9]+[,.]?[0-9]*', fees_text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Match the (number,  symbol) case\n",
    "    right_symbol_matches = re.findall(fr'[0-9]+[,.]?[0-9]*\\s*(?:{symbols})+', fees_text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Merge them\n",
    "    matches = left_symbol_matches + right_symbol_matches\n",
    "\n",
    "    # If we got no matches returns None\n",
    "    if len(matches) == 0 :\n",
    "        return None\n",
    "\n",
    "    for match in matches:\n",
    "        # Remove \",\" or \".\" and change to the right type\n",
    "        number = re.findall('([0-9]+)[.,]*([0-9]*)', match)[0]\n",
    "        number = float(number[0] + number[1])\n",
    "\n",
    "        # Isolate symbol and upper case it (to match exchange_rates_dict codes)\n",
    "        symbol = re.findall(fr'(?i)({symbols})', match)[0].upper()\n",
    "\n",
    "        # Transform symbol into code (if not already a code)\n",
    "        if symbol in currency_symbol_to_code.keys():\n",
    "            symbol = currency_symbol_to_code[symbol]\n",
    "\n",
    "        # Change into USD using the exchange_rates dictionary and append to fees\n",
    "        total_fees.append(number * exchange_rates_dict[symbol])\n",
    "\n",
    "    # Take the max fee and return it\n",
    "    max_fee = round(max(total_fees))\n",
    "    return max_fee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:18.187311Z",
     "start_time": "2023-11-19T15:53:17.640128Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "AED: 3.673\n",
      "AFN: 68.721095\n",
      "ALL: 95.196661\n",
      "AMD: 400.751217\n",
      "ANG: 1.793489\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load latest exchange rates\n",
    "my_app_id = \"1457fcd3d536441baad3ce7918b5025b\"\n",
    "exchange_rates_dict = get_latest_exchange_rates(my_app_id)\n",
    "\n",
    "# Show exchange_rates_dict\n",
    "count = 0\n",
    "print(\"{\")\n",
    "for key, value in exchange_rates_dict.items():\n",
    "    if count < 5:\n",
    "        print(f'{key}: {value}')\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:21.054431Z",
     "start_time": "2023-11-19T15:53:20.940380Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Save preprocessed fees into a new column\n",
    "# #TODO with this preprocessing we have 80% of NaN's, maybe we could do better?\n",
    "data[\"fees_USD\"] = data[\"fees\"].apply(preprocess_fees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:22.261793Z",
     "start_time": "2023-11-19T15:53:22.199618Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fees</th>\n",
       "      <th>fees_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK: £18,000 (Total) International: £34,750 (To...</td>\n",
       "      <td>27896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UK: £13,750 (Total) International: £31,000 (To...</td>\n",
       "      <td>24886.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.000 €</td>\n",
       "      <td>16488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.000 €</td>\n",
       "      <td>16488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuition fee per year (non-EU/EEA students): 15...</td>\n",
       "      <td>13740.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                fees  fees_USD\n",
       "0  Please see the university website for further ...       NaN\n",
       "1  UK: £18,000 (Total) International: £34,750 (To...   27896.0\n",
       "2  Please see the university website for further ...       NaN\n",
       "3  Please see the university website for further ...       NaN\n",
       "4  Please see the university website for further ...       NaN\n",
       "5  UK: £13,750 (Total) International: £31,000 (To...   24886.0\n",
       "6                                           18.000 €   16488.0\n",
       "7                                           18.000 €   16488.0\n",
       "8  Please see the university website for further ...       NaN\n",
       "9  Tuition fee per year (non-EU/EEA students): 15...   13740.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"fees\", \"fees_USD\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Conjunctive query\n",
    "\n",
    "### 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:25.308254Z",
     "start_time": "2023-11-19T15:53:25.254641Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Store all terms contained in the \"clean_description\" as a set\n",
    "terms_set = set(','.join(data[\"clean_description\"]).split(\",\"))\n",
    "\n",
    "# Create a dict that associate each term to a unique id\n",
    "terms_id_dict = {key: value for value, key in enumerate(terms_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:27.510982Z",
     "start_time": "2023-11-19T15:53:27.247659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we create the inverted index dictionary.\n",
    "\n",
    "# Preallocate a dictionary with the form: {term_id : []}\n",
    "inverted_index_dict = {i : [] for i in range(len(terms_id_dict))}\n",
    "\n",
    "# Iterating over all terms and texts in the \"clean_description\" field\n",
    "for i,text in enumerate(data[\"clean_description\"]):\n",
    "    text_list = text.split(\",\")\n",
    "    for term in text_list:\n",
    "\n",
    "        # Get term id\n",
    "        term_id = terms_id_dict[term]\n",
    "\n",
    "        # Add document id \"i\" to the term_id list\n",
    "        inverted_index_dict[term_id].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:28.666413Z",
     "start_time": "2023-11-19T15:53:28.629214Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "0: [487, 532, 694, 770, 796, 908, 950, 1067, 1421, 1779, 1786, 1922, 2098, 2936, 2938, 3221, 3676, 3735, 4362, 4400, 4488, 4597, 5440, 5742]\n",
      "1: [3942]\n",
      "2: [4145]\n",
      "3: [4979]\n",
      "4: [25, 52, 65, 91, 155, 247, 278, 285, 325, 387, 452, 512, 517, 650, 710, 741, 750, 762, 808, 1034, 1050, 1449, 1577, 1667, 1709, 1734, 1741, 1882, 1882, 1882, 1882, 1964, 2282, 2407, 2439, 2583, 2656, 2767, 2783, 2784, 2814, 2853, 2929, 2929, 2929, 2998, 3076, 3076, 3093, 3301, 3446, 3461, 3587, 3684, 3926, 3926, 3926, 4068, 4075, 4077, 4111, 4142, 4175, 4329, 4374, 4375, 4394, 4417, 4418, 4418, 4419, 4419, 4419, 4419, 4420, 4420, 4420, 4420, 4420, 4421, 4421, 4421, 4421, 4421, 4421, 4473, 4560, 4610, 4612, 4629, 4725, 4726, 4920, 4938, 4997, 5070, 5123, 5132, 5137, 5150, 5150, 5150, 5150, 5188, 5357, 5364, 5449, 5801, 5931, 5959]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Show inverted_index_dict structure\n",
    "print(\"{\")\n",
    "count = 0\n",
    "for key, value in inverted_index_dict.items():\n",
    "    if count < 5:\n",
    "        print(f'{key}: {value}')\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:34.829895Z",
     "start_time": "2023-11-19T15:53:34.782557Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This function takes a query as a input and returns the most affine docs:\n",
    "\n",
    "def naive_search_engine(query):\n",
    "    # Apply same preprocessing done for descriptions and split wrt \",\"\n",
    "    query = preprocess_description(query).split(\",\")\n",
    "\n",
    "    # For each term in query get all the docs ids that contain it as a set\n",
    "    query_docs = [set(inverted_index_dict[terms_id_dict[term]]) for term in query]\n",
    "\n",
    "    # Select the docs ids that contain all the query term, and sort them\n",
    "    query_docs = set.intersection(*query_docs)\n",
    "    query_docs = list(sorted(query_docs))\n",
    "\n",
    "    # Return selected columns of those docs\n",
    "    result  = data.iloc[query_docs, [0,1,4,12]]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:36.665686Z",
     "start_time": "2023-11-19T15:53:36.617984Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting and Finance - MSc</td>\n",
       "      <td>University of Leeds</td>\n",
       "      <td>Businesses and governments rely on sound finan...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addictions MSc</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>Join us for an online session for prospective ...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Analytical Toxicology MSc</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>The Analytical Toxicology MSc is a unique stud...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Civil Engineering MSc</td>\n",
       "      <td>University of Greenwich</td>\n",
       "      <td>Meet the future demands of the construction in...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Economics - MSc</td>\n",
       "      <td>University of Leeds</td>\n",
       "      <td>Our MSc Economics allows you to apply economic...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>Master of Science/Postgraduate Diploma in Envi...</td>\n",
       "      <td>The Hong Kong University of Science and Techno...</td>\n",
       "      <td>The program is meant to meet the needs of prac...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>Master Sociology – Social and Economic Psychology</td>\n",
       "      <td>University of Cologne</td>\n",
       "      <td>This programme provides you with:a solid found...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>Masters in Economics</td>\n",
       "      <td>University of Lisbon</td>\n",
       "      <td>OBJECTIVESThe MSc in Economics aims to provide...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>Master's in Global and European Politics</td>\n",
       "      <td>European School of Political and Social Scienc...</td>\n",
       "      <td>Europe and the EU in a changing worldOur inter...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>Masters in Hospitality Management</td>\n",
       "      <td>Ecole hotelière de Lausanne</td>\n",
       "      <td>With our Master in Hospitality Management, you...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             courseName  \\\n",
       "1                          Accounting and Finance - MSc   \n",
       "4                                        Addictions MSc   \n",
       "12                            Analytical Toxicology MSc   \n",
       "48                                Civil Engineering MSc   \n",
       "86                                      Economics - MSc   \n",
       "...                                                 ...   \n",
       "5909  Master of Science/Postgraduate Diploma in Envi...   \n",
       "5937  Master Sociology – Social and Economic Psychology   \n",
       "5957                               Masters in Economics   \n",
       "5963           Master's in Global and European Politics   \n",
       "5965                  Masters in Hospitality Management   \n",
       "\n",
       "                                         universityName  \\\n",
       "1                                   University of Leeds   \n",
       "4                                 King’s College London   \n",
       "12                                King’s College London   \n",
       "48                              University of Greenwich   \n",
       "86                                  University of Leeds   \n",
       "...                                                 ...   \n",
       "5909  The Hong Kong University of Science and Techno...   \n",
       "5937                              University of Cologne   \n",
       "5957                               University of Lisbon   \n",
       "5963  European School of Political and Social Scienc...   \n",
       "5965                        Ecole hotelière de Lausanne   \n",
       "\n",
       "                                            description  \\\n",
       "1     Businesses and governments rely on sound finan...   \n",
       "4     Join us for an online session for prospective ...   \n",
       "12    The Analytical Toxicology MSc is a unique stud...   \n",
       "48    Meet the future demands of the construction in...   \n",
       "86    Our MSc Economics allows you to apply economic...   \n",
       "...                                                 ...   \n",
       "5909  The program is meant to meet the needs of prac...   \n",
       "5937  This programme provides you with:a solid found...   \n",
       "5957  OBJECTIVESThe MSc in Economics aims to provide...   \n",
       "5963  Europe and the EU in a changing worldOur inter...   \n",
       "5965  With our Master in Hospitality Management, you...   \n",
       "\n",
       "                                                    url  \n",
       "1     https://www.findamasters.com/masters-degrees/c...  \n",
       "4     https://www.findamasters.com/masters-degrees/c...  \n",
       "12    https://www.findamasters.com/masters-degrees/c...  \n",
       "48    https://www.findamasters.com/masters-degrees/c...  \n",
       "86    https://www.findamasters.com/masters-degrees/c...  \n",
       "...                                                 ...  \n",
       "5909  https://www.findamasters.com/masters-degrees/c...  \n",
       "5937  https://www.findamasters.com/masters-degrees/c...  \n",
       "5957  https://www.findamasters.com/masters-degrees/c...  \n",
       "5963  https://www.findamasters.com/masters-degrees/c...  \n",
       "5965  https://www.findamasters.com/masters-degrees/c...  \n",
       "\n",
       "[463 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_search_engine(\"advanced knowledge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2.2) Conjunctive query & Ranking score\n",
    "\n",
    "\n",
    "For the second search engine, given a query, we want to get the top-k (the choice of k it's up to you!) documents related to the query. In particular:\n",
    "\n",
    "Find all the documents that contain all the words in the query.\n",
    "Sort them by their similarity with the query.\n",
    "Return in output k documents, or all the documents with non-zero similarity with the query when the results are less than k. You must use a heap data structure (you can use Python libraries) for maintaining the top-k documents.\n",
    "To solve this task, you must use the tfIdf score and the Cosine similarity. The field to consider is still the description. Let's see how.\n",
    "\n",
    "### 2.2.1) Inverted index\n",
    "\n",
    "Your second Inverted Index must be of this format:\n",
    "\n",
    "{\n",
    "term_id_1:[(document1, tfIdf_{term,document1}), (document2, tfIdf_{term,document2}), (document4, tfIdf_{term,document4}), ...],\n",
    "term_id_2:[(document1, tfIdf_{term,document1}), (document3, tfIdf_{term,document3}), (document5, tfIdf_{term,document5}), (document6, tfIdf_{term,document6}), ...],\n",
    "...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:46.869270Z",
     "start_time": "2023-11-19T15:53:43.970420Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we create the second inverted index dictionary.\n",
    "\n",
    "# Preallocate a dictionary with the form: {term_id : []}\n",
    "inverted_index_dict_with_scores = {i : [] for i in range(len(terms_id_dict))}\n",
    "\n",
    "# Iterating over all terms and texts in the \"clean_description\" field\n",
    "for i,text in enumerate(data[\"clean_description\"]):\n",
    "    text_list = text.split(\",\")\n",
    "\n",
    "    # Set here has the purpose of selecting unique terms only.\n",
    "    # We don't want to insert in inverted_2 dict multiple times the same score\n",
    "    for term in set(text_list):\n",
    "\n",
    "        # Get term id\n",
    "        term_id = terms_id_dict[term]\n",
    "\n",
    "        # Get idf score: total number of documents / number of documents term is in\n",
    "        term_idf = len(data[\"clean_description\"]) / len(inverted_index_dict[term_id])\n",
    "\n",
    "        # Get tf score: number of times term appears in text / total number of terms in text\n",
    "        term_tf =  sum([word == term for word in text_list]) / len(text_list)\n",
    "\n",
    "        # Compute tfidf score\n",
    "        term_tfidf = term_tf * term_idf\n",
    "\n",
    "        # Update new_inverted list\n",
    "        inverted_index_dict_with_scores[term_id].append((i , term_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:47.793861Z",
     "start_time": "2023-11-19T15:53:47.772663Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "0: [(487, 250.0), (532, 250.0), (694, 250.0), (770, 250.0), (796, 250.0), (908, 250.0), (950, 250.0), (1067, 250.0), (1421, 250.0), (1779, 250.0), (1786, 250.0), (1922, 250.0), (2098, 250.0), (2936, 250.0), (2938, 250.0), (3221, 250.0), (3676, 250.0), (3735, 250.0), (4362, 250.0), (4400, 250.0), (4488, 250.0), (4597, 250.0), (5440, 250.0), (5742, 250.0)]\n",
      "1: [(3942, 103.44827586206897)]\n",
      "2: [(4145, 81.08108108108108)]\n",
      "3: [(4979, 37.5)]\n",
      "4: [(25, 1.4742014742014744), (52, 1.048951048951049), (65, 0.8141112618724559), (91, 0.9244992295839753), (155, 0.9404388714733543), (247, 1.3303769401330379), (278, 0.9917355371900827), (285, 1.948051948051948), (325, 0.7177033492822966), (387, 0.8797653958944281), (452, 1.0695187165775402), (512, 0.7905138339920948), (517, 3.896103896103896), (650, 0.9090909090909091), (710, 0.8797653958944281), (741, 0.6128702757916241), (750, 0.9244992295839753), (762, 0.9569377990430622), (808, 0.9090909090909091), (1034, 0.8941877794336811), (1050, 0.9404388714733543), (1449, 1.2684989429175475), (1577, 1.090909090909091), (1667, 0.9404388714733543), (1709, 0.9244992295839753), (1734, 1.048951048951049), (1741, 1.1131725417439702), (1882, 3.463203463203463), (1964, 0.8264462809917356), (2282, 0.9404388714733543), (2407, 1.048951048951049), (2439, 3.0303030303030303), (2583, 0.9917355371900827), (2656, 3.2085561497326203), (2767, 1.3303769401330379), (2783, 1.5151515151515151), (2784, 1.2987012987012987), (2814, 0.9917355371900827), (2853, 0.9569377990430622), (2929, 3.339517625231911), (2998, 1.1605415860735009), (3076, 1.9834710743801653), (3093, 1.1363636363636362), (3301, 0.9404388714733543), (3446, 0.7792207792207793), (3461, 1.3986013986013985), (3587, 0.9244992295839753), (3684, 0.9090909090909091), (3926, 6.293706293706294), (4068, 0.6493506493506493), (4075, 0.8021390374331551), (4077, 1.2396694214876034), (4111, 1.2396694214876034), (4142, 1.4742014742014744), (4175, 1.7045454545454546), (4329, 1.4354066985645932), (4374, 0.9090909090909091), (4375, 1.1131725417439702), (4394, 1.7045454545454546), (4417, 1.1131725417439702), (4418, 5.194805194805195), (4419, 3.761755485893417), (4420, 4.329004329004329), (4421, 5.844155844155844), (4473, 1.3986013986013985), (4560, 0.9404388714733543), (4610, 0.9917355371900827), (4612, 1.0101010101010102), (4629, 0.8941877794336811), (4725, 0.8658008658008658), (4726, 0.9090909090909091), (4920, 0.8797653958944281), (4938, 0.9244992295839753), (4997, 0.9917355371900827), (5070, 0.9404388714733543), (5123, 1.4354066985645932), (5132, 0.8522727272727273), (5137, 1.1605415860735009), (5150, 4.278074866310161), (5188, 0.9404388714733543), (5357, 0.9404388714733543), (5364, 1.2684989429175475), (5449, 0.8658008658008658), (5801, 0.9404388714733543), (5931, 0.9244992295839753), (5959, 1.048951048951049)]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Show inverted_index_dict_with_scores structure\n",
    "print(\"{\")\n",
    "count = 0\n",
    "for key, value in inverted_index_dict_with_scores.items():\n",
    "    if count < 5:\n",
    "        print(f'{key}: {value}')\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:30:23.623200Z",
     "start_time": "2023-11-19T15:30:23.560339Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we define our second search engine\n",
    "\n",
    "# This function computes from scratch cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "\n",
    "    # Calculate the norms\n",
    "    norm_vec_1 = np.linalg.norm(vec1)\n",
    "    norm_vec_2 = np.linalg.norm(vec2)\n",
    "\n",
    "    # Compute the cosine similarity\n",
    "    cos_sim = np.dot(vec1, vec2) / (norm_vec_1 * norm_vec_2)\n",
    "\n",
    "    return cos_sim\n",
    "\n",
    "\n",
    "def  top_k_search_engine(query, k):\n",
    "\n",
    "    # Apply same preprocessing done for descriptions and split wrt \",\"\n",
    "    query = preprocess_description(query).split(\",\")\n",
    "\n",
    "    # Get query terms ids\n",
    "    query_ids = [terms_id_dict[term] for term in query]\n",
    "\n",
    "    # Calculate for each term in query its tfidf score\n",
    "    query_idf = np.array([len(data[\"clean_description\"]) / len(inverted_index_dict[term_id]) for term_id in query_ids])\n",
    "    query_tf =  np.array([sum([word == term for word in query]) / len(query) for term in query]) # change this\n",
    "    query_tfidf = query_idf * query_tf\n",
    "\n",
    "    # Get the indexes of docs that contain all terms in query using inverted_1\n",
    "    docs_ids = [set(inverted_index_dict[term_id]) for term_id in query_ids]\n",
    "    appropriate_docs_ids = list(set.intersection(*docs_ids))\n",
    "\n",
    "    # docs_tfidf will contain, for each id in appropriate_docs_ids, its tfidf vectorial representation.\n",
    "    docs_tfidf = {i : [] for i in appropriate_docs_ids}\n",
    "\n",
    "    # For each term in the query we retrieve its inverted_2 list of tuples\n",
    "    for term_id in query_ids:\n",
    "        list_of_tuples = inverted_index_dict_with_scores[term_id]\n",
    "        for tuple_doc in list_of_tuples:\n",
    "\n",
    "            # When we encounter a tuple with an appropriate doc id  we add its tfidf score in docs_tfidf\n",
    "            if tuple_doc[0] in appropriate_docs_ids:\n",
    "                docs_tfidf[tuple_doc[0]].append(tuple_doc[1])\n",
    "\n",
    "    # Transform into a list\n",
    "    docs_tfidf = list(docs_tfidf.values())\n",
    "\n",
    "    # Compute cosine similarities between query_tfidf and each doc_tfidf\n",
    "    cos_sims = [cosine_similarity(query_tfidf, doc_tfidf) for doc_tfidf in docs_tfidf]\n",
    "\n",
    "    # Select all appropriate_docs_ids from data and specified columns\n",
    "    result  = data.iloc[appropriate_docs_ids, [0,1,4,12]]\n",
    "\n",
    "    # Add the cosine similarity score and sort the dataframe\n",
    "    result[\"cos_sim\"] = cos_sims\n",
    "    result = result.sort_values(by='cos_sim', ascending=False)\n",
    "\n",
    "    # Get, if possible, just the top k\n",
    "    if k < result.shape[0]:\n",
    "        result = result[:k]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:30:24.991055Z",
     "start_time": "2023-11-19T15:30:24.934180Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>Geo-information Science and Earth Observation MSc</td>\n",
       "      <td>University of Twente</td>\n",
       "      <td>INTERESTED IN A CAREER IN SPATIAL DATA SCIENCE...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>Clinical Ophthalmic Practice MSc</td>\n",
       "      <td>University College London</td>\n",
       "      <td>Register your interest in graduate study at UC...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>LSE-Peking University Double Degree MSc Enviro...</td>\n",
       "      <td>London School of Economics and Political Science</td>\n",
       "      <td>Ask LSEOrganised jointly by LSE and Peking Uni...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>Countering Extremist Crime and Terrorism MSc</td>\n",
       "      <td>University College London</td>\n",
       "      <td>Register your interest in graduate study at UC...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>International Money and Banking - MSc</td>\n",
       "      <td>University of Birmingham</td>\n",
       "      <td>The correlation between macroeconomics, bankin...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Biomaterials and Tissue Engineering MSc</td>\n",
       "      <td>University College London</td>\n",
       "      <td>Register your interest in graduate study at UC...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Advanced Design and Manufacturing - MSc</td>\n",
       "      <td>University of Northampton</td>\n",
       "      <td>Our Advanced Design and Manufacturing MSc addr...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>Geographical Information Systems and Environme...</td>\n",
       "      <td>University of Brighton</td>\n",
       "      <td>Environmental issues are a global concern. Our...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>Diagnostic Radiography MSc</td>\n",
       "      <td>University College Cork</td>\n",
       "      <td>Our MSc Diagnostic Radiography programme is an...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5576</th>\n",
       "      <td>Master of Chemistry (Leuven)</td>\n",
       "      <td>KU Leuven</td>\n",
       "      <td>Breakthroughs in chemistry can change the text...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             courseName  \\\n",
       "3993  Geo-information Science and Earth Observation MSc   \n",
       "2041                   Clinical Ophthalmic Practice MSc   \n",
       "5120  LSE-Peking University Double Degree MSc Enviro...   \n",
       "2436       Countering Extremist Crime and Terrorism MSc   \n",
       "4897              International Money and Banking - MSc   \n",
       "1496            Biomaterials and Tissue Engineering MSc   \n",
       "764             Advanced Design and Manufacturing - MSc   \n",
       "3981  Geographical Information Systems and Environme...   \n",
       "2818                         Diagnostic Radiography MSc   \n",
       "5576                       Master of Chemistry (Leuven)   \n",
       "\n",
       "                                        universityName  \\\n",
       "3993                              University of Twente   \n",
       "2041                         University College London   \n",
       "5120  London School of Economics and Political Science   \n",
       "2436                         University College London   \n",
       "4897                          University of Birmingham   \n",
       "1496                         University College London   \n",
       "764                          University of Northampton   \n",
       "3981                            University of Brighton   \n",
       "2818                           University College Cork   \n",
       "5576                                         KU Leuven   \n",
       "\n",
       "                                            description  \\\n",
       "3993  INTERESTED IN A CAREER IN SPATIAL DATA SCIENCE...   \n",
       "2041  Register your interest in graduate study at UC...   \n",
       "5120  Ask LSEOrganised jointly by LSE and Peking Uni...   \n",
       "2436  Register your interest in graduate study at UC...   \n",
       "4897  The correlation between macroeconomics, bankin...   \n",
       "1496  Register your interest in graduate study at UC...   \n",
       "764   Our Advanced Design and Manufacturing MSc addr...   \n",
       "3981  Environmental issues are a global concern. Our...   \n",
       "2818  Our MSc Diagnostic Radiography programme is an...   \n",
       "5576  Breakthroughs in chemistry can change the text...   \n",
       "\n",
       "                                                    url  cos_sim  \n",
       "3993  https://www.findamasters.com/masters-degrees/c...      1.0  \n",
       "2041  https://www.findamasters.com/masters-degrees/c...      1.0  \n",
       "5120  https://www.findamasters.com/masters-degrees/c...      1.0  \n",
       "2436  https://www.findamasters.com/masters-degrees/c...      1.0  \n",
       "4897  https://www.findamasters.com/masters-degrees/c...      1.0  \n",
       "1496  https://www.findamasters.com/masters-degrees/c...      1.0  \n",
       "764   https://www.findamasters.com/masters-degrees/c...      1.0  \n",
       "3981  https://www.findamasters.com/masters-degrees/c...      1.0  \n",
       "2818  https://www.findamasters.com/masters-degrees/c...      1.0  \n",
       "5576  https://www.findamasters.com/masters-degrees/c...      1.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_search_engine(\"advanced knowledge\", k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BONUS: More complex search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pice of code, read the dataset, and then accepts queries from user in 2 ways.\n",
    "1. User can search dataset based on 'course_name, university_name, university_city, fee_min, fee_max, countries, started_only, online_only'. User can specify none, all or some of them to retrive the desired rows.\n",
    "2. User can Write a sentence as query that searches through course_name, university_name, university_city, and based on the most similarity, the data will be returned. For the other options, user should explicitly specify them as argument to the search_courses() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the dataset we are going to work with\n",
    "data = pd.read_table(r\"dataset.tsv\")  # Read the dataset from a tab-separated file\n",
    "\n",
    "from collections import defaultdict  # Import defaultdict from the collections module\n",
    "import math  # Import the math module for mathematical operations\n",
    "\n",
    "def tokenize(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.lower().split()  # Convert text to lowercase and split into tokens\n",
    "    return []  # Return an empty list for non-string values\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(query_tokens, doc_tokens):\n",
    "    query_vector = defaultdict(int)  # Create a dictionary to store query token frequencies\n",
    "    doc_vector = defaultdict(int)  # Create a dictionary to store document token frequencies\n",
    "\n",
    "    # Calculate term frequencies for query and document\n",
    "    for token in query_tokens:\n",
    "        query_vector[token] += 1  # Increment token frequency in the query vector\n",
    "    for token in doc_tokens:\n",
    "        doc_vector[token] += 1  # Increment token frequency in the document vector\n",
    "\n",
    "    # Compute dot product\n",
    "    dot_product = sum(query_vector[token] * doc_vector[token] for token in query_tokens if token in doc_tokens)\n",
    "\n",
    "    # Calculate magnitudes\n",
    "    query_magnitude = math.sqrt(sum(query_vector[token] ** 2 for token in query_tokens))\n",
    "    doc_magnitude = math.sqrt(sum(doc_vector[token] ** 2 for token in doc_tokens))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if query_magnitude != 0 and doc_magnitude != 0:\n",
    "        similarity = dot_product / (query_magnitude * doc_magnitude)  # Calculate cosine similarity\n",
    "        return similarity\n",
    "    else:\n",
    "        return 0.0  # Return 0 if either magnitude is zero\n",
    "\n",
    "# Function to retrieve documents based on similarity\n",
    "def retrieve_similar_documents(query, inverted_indexes, search_results):\n",
    "    query_tokens = tokenize(query)  # Tokenize the query\n",
    "\n",
    "    # Aggregate similarity scores for each document\n",
    "    similarity_scores = defaultdict(float)  # Create a dictionary for similarity scores\n",
    "    for token in query_tokens:\n",
    "        if token in inverted_indexes:\n",
    "            postings = inverted_indexes[token]\n",
    "            for doc_id, relevance in postings:\n",
    "                doc_tokens = tokenize(search_results.loc[doc_id, 'courseName'] + \" \" + \n",
    "                                      search_results.loc[doc_id, 'universityName'] + \" \" +\n",
    "                                      search_results.loc[doc_id, 'city'])\n",
    "                similarity = cosine_similarity(query_tokens, doc_tokens)\n",
    "                similarity_scores[doc_id] += similarity * relevance  # Weighted sum of similarities\n",
    "\n",
    "    # Sort documents by aggregated similarity\n",
    "    sorted_docs = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_docs\n",
    "\n",
    "def parse_custom_date(date):\n",
    "    try:\n",
    "        return datetime.strptime(date, \"%B\")  # Add the correct date format for parsing\n",
    "    except ValueError:\n",
    "        return pd.NaT  # Return NaT (Not a Timestamp) for invalid dates\n",
    "\n",
    "def get_current_month_name():\n",
    "    current_month_number = datetime.now().month\n",
    "    return month_names[current_month_number - 1]  # Adjust index to match the list\n",
    "\n",
    "def filter_started_courses(data):\n",
    "    current_month_name = get_current_month_name()\n",
    "    month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    current_month_index = month_names.index(current_month_name)\n",
    "\n",
    "    data = data[data['startDate'].notna()]  # Omit rows where 'startDate' is NaT\n",
    "    data['start_months'] = data['startDate'].apply(lambda x: x.split(', '))  # Split multiple months into a list\n",
    "\n",
    "    def has_started(start_months):\n",
    "        for month in start_months:\n",
    "            if month in month_names:\n",
    "                month_index = month_names.index(month)\n",
    "                if month_index <= current_month_index:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    data = data.copy()\n",
    "    data.loc[:, 'has_started'] = data['start_months'].apply(has_started)  # Using .loc to assign the column\n",
    "\n",
    "    data = data[data['has_started']]\n",
    "\n",
    "    data.drop(columns=['start_months', 'has_started'], inplace=True)  # Drop helper columns\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def filter_online_modality(data):\n",
    "    data_copy = data.copy()  # Create a copy of the DataFrame to avoid chained assignment warnings\n",
    "    return data_copy[data_copy['administration'].str.contains('Online', case=False, na=False, regex=False)]\n",
    "\n",
    "def search_courses(data, query=None, course_name=None, university_name=None, university_city=None, fee_min=None, fee_max=None, countries=None, started_only=False, online_only=False):\n",
    "    if query:\n",
    "\n",
    "        # Create a dictionary to hold inverted indexes\n",
    "        inverted_indexes = {}\n",
    "        for index, row in search_results.iterrows():\n",
    "            # Tokenize relevant fields\n",
    "            course_tokens = tokenize(row['courseName'])\n",
    "            university_tokens = tokenize(row['universityName'])\n",
    "            city_tokens = tokenize(row['city'])\n",
    "        \n",
    "            # Update inverted indexes for each token\n",
    "            for token in course_tokens + university_tokens + city_tokens:\n",
    "                if token not in inverted_indexes:\n",
    "                    inverted_indexes[token] = []\n",
    "                inverted_indexes[token].append((index, 1))  # Assuming relevance of 1 for simplicity\n",
    "\n",
    "        similar_docs = retrieve_similar_documents(query, inverted_indexes, search_results)\n",
    "\n",
    "        # Retrieve top N documents based on similarity\n",
    "        top_n = 50  # Number of top documents to retrieve\n",
    "        top_documents = [doc_id for doc_id, similarity in similar_docs[:top_n]]\n",
    "        relevant_results = search_results.loc[top_documents]\n",
    "        # data = data[data.index.isin(top_documents)]\n",
    "        data = relevant_results\n",
    "\n",
    "    # Handling special case for fees (preprocess_fees function needs to be defined)\n",
    "    data['fees'] = data['fees'].apply(lambda x: 0 if x == \"Please see the university website for further information on fees for this course.\" else x)\n",
    "    data[\"fees_USD\"] = data[\"fees\"].apply(preprocess_fees)  # Add preprocess_fees function\n",
    "\n",
    "    # Filtering based on optional queries\n",
    "    if course_name:\n",
    "        data = data[data['courseName'].str.contains(course_name, case=False, na=False, regex=False)]\n",
    "    if university_name:\n",
    "        data = data[data['universityName'].str.contains(university_name, case=False, na=False, regex=False)]\n",
    "    if university_city:\n",
    "        data = data[data['city'].str.contains(university_city, case=False, na=False, regex=False)]\n",
    "\n",
    "    # Filtering based on fee range\n",
    "    if fee_min is not None:\n",
    "        data = data[data['fees_USD'].astype(float).fillna(0) >= fee_min]\n",
    "    if fee_max is not None:\n",
    "        data = data[data['fees_USD'].astype(float).fillna(0) <= fee_max]\n",
    "\n",
    "    # Filtering based on countries\n",
    "    if countries:\n",
    "        data = data[data['country'].isin(countries)]\n",
    "\n",
    "    # Filter for courses that have started\n",
    "    if started_only:\n",
    "        data = filter_started_courses(data)\n",
    "\n",
    "    # Filter for online modality\n",
    "    if online_only:\n",
    "        data = filter_online_modality(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage\n",
    "- Pass your optional queries to the search_courses function\n",
    "- Replace None with the desired search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "filtered_data = search_courses(data,\n",
    "                                query=\"Computer science courses in Newcastle\",\n",
    "                                fee_min=5000,  # Replace with your minimum fee\n",
    "                                fee_max=10000,  # Replace with your maximum fee\n",
    "                                countries=[\"United Kingdom\"],  # List of desired countries\n",
    "                                started_only=True, # Filter for courses that have started in the current month\n",
    "                                online_only=True)  # Filter for online modality\n",
    "\n",
    "filtered_data  # Displaying the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "filtered_data = search_courses(data,\n",
    "                                query=\"Portland universities\",\n",
    "                                fee_min=None,  # Replace with your minimum fee\n",
    "                                fee_max=None,  # Replace with your maximum fee\n",
    "                                countries=[],  # List of desired countries\n",
    "                                started_only=False, # Filter for courses that have started in the current month\n",
    "                                online_only=False)  # Filter for online modality\n",
    "\n",
    "filtered_data  # Displaying the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "search_results = search_courses(data,\n",
    "                                course_name=None,\n",
    "                                university_name=None,\n",
    "                                university_city=None,\n",
    "                                fee_min=None,  # Replace with your minimum fee\n",
    "                                fee_max=None,  # Replace with your maximum fee\n",
    "                                countries=[],  # List of desired countries\n",
    "                                started_only=True, # Filter for courses that have started in the current month\n",
    "                                online_only=False)  # Filter for online modality\n",
    "\n",
    "# search_results[['courseName', 'universityName', 'url']]\n",
    "search_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
