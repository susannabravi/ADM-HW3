{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Federico\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:48:19.781439Z",
     "end_time": "2023-11-19T14:48:22.770947Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data collection\n",
    "\n",
    "## 1.1. Get the list of master's degree courses\n",
    "We created a file named 'urls.txt' that contains all the urls associated with the url of each master page.\n",
    "for reaching such purpose, we iterate over all 400 pages and took the link for every 15 urls of each page.\n",
    "we stored all urls in 'urls.txt' file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:29:57.119032Z",
     "end_time": "2023-11-18T16:31:44.436742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"urls.txt\" file is generated!\n"
     ]
    }
   ],
   "source": [
    "f = open(\"urls.txt\",\"w\") # First we create a txt file where we can write the URLs  #  w means writing mode\n",
    "for i in range(1, 401): #from first page to page 400\n",
    "    url = f\"https://www.findamasters.com/masters-degrees/msc-degrees/?PG={i}\" #pages can be scrolled by changing the number after PG\n",
    "    result = requests.get(url) # as we have done in class\n",
    "    soup = BeautifulSoup(result.text, 'html.parser') # to get the html of each page\n",
    "\n",
    "    for link in soup.find_all(class_ = re.compile('courseLink')): #as in class to get each tag of the page which belongs to class courseLink\n",
    "        c = (link.get(\"href\"))  # url of each page in the i-th page\n",
    "        f.write(\"https://www.findamasters.com/\"+c) #writing the rows\n",
    "        f.write(\"\\n\")\n",
    "f.close()\n",
    "print('The \"urls.txt\" file is generated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl master's degree pages\n",
    "\n",
    "We wrote a function named 'download_url'.\n",
    "Since the FindMaster website blocks us for 70 seconds for every (20 to 22) requests we send, we use 'time.sleep(70)' to wait and then resend the http get request. \n",
    "we also omit to download the http files that their directory are already existed.\n",
    "\n",
    "for sending http get requests asynchronously, we can use async and await methods and take the advantage of using \"aiohttp\" library. the other way is to use ThreadPoolExecutor function executer. \n",
    "It means that we store the executer command in a variable named 'future_to_url' that we are able to call in the future.\n",
    "The ThreadPoolExecutor is a built-in Python module that provides managing a pool of worker threads. It allows us to submit tasks to the pool, which are then executed by one of the worker threads in the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All HTML files are stored in the HTML_folders directory.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Function to download and save HTML for a given URL\n",
    "def download_url(url, folder_path, page_number):\n",
    "    # Create a folder for each page if it doesn't exist\n",
    "    page_folder = os.path.join(folder_path, f\"page_{page_number}\")\n",
    "    if os.path.exists(page_folder):\n",
    "        # uncomment the below code to see which pages are skiped, cause they have already been downloaded.\n",
    "        # print(f\"Skipping Page: {page_number} - Folder already exists.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url) # Send a GET request to the URL\n",
    "        response.raise_for_status()  # Raise an exception for bad responses \n",
    "\n",
    "        # Create a folder for each page if it doesn't exist\n",
    "        os.makedirs(page_folder, exist_ok=True)\n",
    "\n",
    "        # Save the HTML content to a file\n",
    "        file_path = os.path.join(page_folder, f\"html_{page_number}.html\")\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"Downloaded page {page_number}: {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download page {page_number}: {url}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Retrying in 70 seconds...\")\n",
    "        time.sleep(70)  # Wait for 10 seconds before retrying\n",
    "        download_url(url, folder_path, page_number)  # Retry the download\n",
    "\n",
    "# Read all URLs one by one\n",
    "with open('urls.txt', 'r') as urls_file:\n",
    "    urls = urls_file.read().splitlines()\n",
    "\n",
    "output_folder = 'HTML_folders' # Store all HTML files into this directory.\n",
    "\n",
    "# We can use ThreadPoolExecutor for sending http requests asynchronously. \n",
    "# However, Since the FindMaster website blocks us for 70 seconds for every (20 to 22) requests we send, \n",
    "# the max_workers in below code assigned to number 1. So it sends requests synchronously.\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    # Enumerate through each URL and submit download tasks to the executor\n",
    "    future_to_url = {executor.submit(download_url, url, output_folder, page_number): url for page_number, url in enumerate(urls, start=1)}\n",
    "\n",
    "print(\"All HTML files are stored in the HTML_folders directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages\n",
    "Here we create a '.tsv' file including the following columns for each of the HTML files.\n",
    "\n",
    "1. Course Name (to save as ```courseName```): string;\n",
    "2. University (to save as ```universityName```): string;\n",
    "3. Faculty (to save as ```facultyName```): string\n",
    "4. Full or Part Time (to save as ```isItFullTime```): string;\n",
    "5. Short Description (to save as ```description```): string;\n",
    "6. Start Date (to save as ```startDate```): string;\n",
    "7. Fees (to save as ```fees```): string;\n",
    "8. Modality (to save as ```modality```):string;\n",
    "9. Duration (to save as ```duration```):string;\n",
    "10. City (to save as ```city```): string;\n",
    "11. Country (to save as ```country```): string;\n",
    "12. Presence or online modality (to save as ```administration```): string;\n",
    "13. Link to the page (to save as ```url```): string.\n",
    "\n",
    "Then, we merge all those files together to generate our final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All HTML files have been read and all .tsv files have been generated.\n"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "# '/Users/armanfeili/Arman/Sapienza Courses/ADM/Homeworks/HW3/phase-2/ADM-HW3/HTML_folders'\n",
    "\n",
    "for i in range(1,6001):\n",
    "    # os.chdir(r'C:\\Users\\susan\\Documents\\DS\\ADM\\HW3\\ADM-HW3\\HTML_folders\\page_'+str(i)) #change directories\n",
    "    os.chdir(r'/Users/armanfeili/Arman/Sapienza Courses/ADM/Homeworks/HW3/phase-3/ADM-HW3/HTML_folders/page_'+str(i)) #change directories\n",
    "    \n",
    "    for filename in os.listdir(os.getcwd()): # get all the files in a folder\n",
    "        if filename.endswith(\".tsv\"): continue # tsv file is already generated.\n",
    "        elif filename.endswith(\".html\"): # if file extension is .html\n",
    "            with open(os.path.join(os.getcwd(), filename), 'r',encoding='utf-8') as f: # open each file into a folder\n",
    "                soup = BeautifulSoup(f,'html.parser') # get the html file by each file \n",
    "                out=[] # initialize a list where we append all the informations parsed from each html file\n",
    "\n",
    "                # 1  Course Name\n",
    "                courseName = soup.find_all(class_=re.compile(\"course-header__course-title\"))\n",
    "                out.append(courseName[0].text.strip() if courseName else \"\") #text.strip to eliminate strange simbols for the space\n",
    "                # 2  University\n",
    "                universityName = soup.find_all(class_=re.compile(\"course-header__institution\"))\n",
    "                out.append(universityName[0].text if universityName else \"\")\n",
    "                # 3  Faculty\n",
    "                facultyName = soup.find_all(class_=re.compile(\"course-header__department\"))\n",
    "                out.append(facultyName[0].text if facultyName else \"\")\n",
    "                # 4  Full or Part Time\n",
    "                isItFullTime = soup.find_all(class_=re.compile(\"concealLink\"))\n",
    "                out.append(isItFullTime[0].text if isItFullTime else \"\")\n",
    "                # 5  Short Description\n",
    "                description = soup.find_all(class_=re.compile(\"course-sections__content\"))\n",
    "                out.append(description[0].text.replace('\\n', '') if description else \"\")\n",
    "                # 6  Start Date\n",
    "                startDate = soup.find_all(class_=re.compile(\"key-info__start-date\"))\n",
    "                out.append(startDate[0].text if startDate else \"\")\n",
    "                # 7  Fees \n",
    "                fees_elements = soup.find_all(class_=re.compile(\"course-sections__fees\")) # taking the fee\n",
    "                fees_text = fees_elements[0].text.replace('\\n', '') if fees_elements else \"\" \n",
    "                cleaned_fees = re.sub(r'Fees', '', fees_text)  # To not \"Fees\" at the beginning \n",
    "                out.append(cleaned_fees.strip() if cleaned_fees else \"\")\n",
    "                # 8  Modality\n",
    "                modality = soup.find_all(class_=re.compile(\"key-info__qualification\"))\n",
    "                out.append(modality[0].text if modality else \"\")\n",
    "                # 9  Duration\n",
    "                duration = soup.find_all(class_=re.compile(\"key-info__duration\"))\n",
    "                out.append(duration[0].text if duration else \"\")\n",
    "                # 10  City\n",
    "                city = soup.find_all(class_=re.compile(\"course-data__city\"))\n",
    "                out.append(city[0].text if city else \"\")\n",
    "                # 11  Country\n",
    "                country = soup.find_all(class_=re.compile(\"course-data__country\"))\n",
    "                out.append(country[0].text if country else \"\")\n",
    "                # 12  Presence or online modality\n",
    "                # We have seen that some courses has both online or oncampus modality, one of them is \"Master of Business Administration\"\n",
    "                on_campus_elements = soup.find_all(class_=re.compile(\"course-data__on-campus\"))\n",
    "                online_elements = soup.find_all(class_=re.compile(\"course-data__online\"))\n",
    "                if on_campus_elements and online_elements:\n",
    "                    out.append(\"both\")\n",
    "                else:\n",
    "                    out.append(on_campus_elements[0].text if on_campus_elements else online_elements[0].text if online_elements else \"Nan\")\n",
    "                # 13  Link to the page\n",
    "                out.append(soup.find('link', {'rel': 'canonical'}).get('href') if soup.find('link', {'rel': 'canonical'}) else \"Nan\")\n",
    "                f.close()\n",
    "                \n",
    "                # Creating file .tsv\n",
    "                l = ['courseName','universityName','facultyName','isItFullTime','description','startDate','fees','modality','duration',\n",
    "                    'city','country','administration','url']\n",
    "                with open(filename+'.tsv','w',encoding='utf-8') as tsv:\n",
    "                    tsv_output = csv.writer(tsv, delimiter='\\t')\n",
    "                    tsv_output.writerow(l)\n",
    "                    tsv_output.writerow(out)\n",
    "    os.chdir('..')  \n",
    "\n",
    "print(\"All HTML files have been read and all .tsv files have been generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.tsv file has been generated as the main dataset.\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "# to merge all the .tsv files\n",
    "for i in range(1,6001):\n",
    "    # os.chdir(r'./HTML_folders/page_'+str(i)) #change directories\n",
    "    os.chdir(r'/Users/armanfeili/Arman/Sapienza Courses/ADM/Homeworks/HW3/phase-3/ADM-HW3/HTML_folders/page_'+str(i)) #change directories\n",
    "    for filename in os.listdir(os.getcwd()):\n",
    "        if filename.endswith(\".tsv\"):\n",
    "            a = pd.read_csv(filename,sep='\\t')\n",
    "            data.append(a)\n",
    "    os.chdir('..')\n",
    "data=pd.concat(data,ignore_index=True)   \n",
    "data.to_csv('../dataset.tsv',sep='\\t',index=False) # Saving the big one\n",
    "print(\"dataset.tsv file has been generated as the main dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Design for Virtual Environments - MSc</td>\n",
       "      <td>Glasgow Caledonian University</td>\n",
       "      <td>School of Engineering and Built Environment</td>\n",
       "      <td>Full time</td>\n",
       "      <td>3D visualisation and animation play a role in ...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full-time</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting and Finance - MSc</td>\n",
       "      <td>University of Leeds</td>\n",
       "      <td>Leeds University Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Businesses and governments rely on sound finan...</td>\n",
       "      <td>September</td>\n",
       "      <td>UK: £18,000 (Total) International: £34,750 (To...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accounting, Accountability &amp; Financial Managem...</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>King’s Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Our Accounting, Accountability &amp; Financial Man...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year FT</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accounting, Financial Management and Digital B...</td>\n",
       "      <td>University of Reading</td>\n",
       "      <td>Henley Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Embark on a professional accounting career wit...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time</td>\n",
       "      <td>Reading</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addictions MSc</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>Institute of Psychiatry, Psychology and Neuros...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Join us for an online session for prospective ...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>One year FT</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          courseName  \\\n",
       "0           3D Design for Virtual Environments - MSc   \n",
       "1                       Accounting and Finance - MSc   \n",
       "2  Accounting, Accountability & Financial Managem...   \n",
       "3  Accounting, Financial Management and Digital B...   \n",
       "4                                     Addictions MSc   \n",
       "\n",
       "                  universityName  \\\n",
       "0  Glasgow Caledonian University   \n",
       "1            University of Leeds   \n",
       "2          King’s College London   \n",
       "3          University of Reading   \n",
       "4          King’s College London   \n",
       "\n",
       "                                         facultyName isItFullTime  \\\n",
       "0        School of Engineering and Built Environment    Full time   \n",
       "1                   Leeds University Business School    Full time   \n",
       "2                             King’s Business School    Full time   \n",
       "3                             Henley Business School    Full time   \n",
       "4  Institute of Psychiatry, Psychology and Neuros...    Full time   \n",
       "\n",
       "                                         description  startDate  \\\n",
       "0  3D visualisation and animation play a role in ...  September   \n",
       "1  Businesses and governments rely on sound finan...  September   \n",
       "2  Our Accounting, Accountability & Financial Man...  September   \n",
       "3  Embark on a professional accounting career wit...  September   \n",
       "4  Join us for an online session for prospective ...  September   \n",
       "\n",
       "                                                fees modality  \\\n",
       "0  Please see the university website for further ...      MSc   \n",
       "1  UK: £18,000 (Total) International: £34,750 (To...      MSc   \n",
       "2  Please see the university website for further ...      MSc   \n",
       "3  Please see the university website for further ...      MSc   \n",
       "4  Please see the university website for further ...      MSc   \n",
       "\n",
       "           duration     city         country administration  \\\n",
       "0  1 year full-time  Glasgow  United Kingdom      On Campus   \n",
       "1  1 year full time    Leeds  United Kingdom      On Campus   \n",
       "2         1 year FT   London  United Kingdom      On Campus   \n",
       "3  1 year full time  Reading  United Kingdom      On Campus   \n",
       "4       One year FT   London  United Kingdom      On Campus   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.findamasters.com/masters-degrees/c...  \n",
       "1  https://www.findamasters.com/masters-degrees/c...  \n",
       "2  https://www.findamasters.com/masters-degrees/c...  \n",
       "3  https://www.findamasters.com/masters-degrees/c...  \n",
       "4  https://www.findamasters.com/masters-degrees/c...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An illustration to the dataset:\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load the dataset we are going to work with\n",
    "data = pd.read_table(r\"dataset.tsv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:48:27.721134Z",
     "end_time": "2023-11-19T14:48:27.815942Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.0 Preprocessing\n",
    "\n",
    "### 2.0.0)  Preprocessing the text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# This function takes a text, removes special cases, punctuations and stop-words then\n",
    "# it applies stemming and finally returns the preprocessed words separated by commas.\n",
    "# TODO maybe they want to apply this to the whole data, not just description\n",
    "def preprocess_description(description_text):\n",
    "\n",
    "    # Handle the cases of float type (there are 24)\n",
    "    if type(description_text) != str:\n",
    "        return \"\"\n",
    "\n",
    "    # Remove all special chars and punctuations\n",
    "    description_text = re.sub(\"[^a-z A-Z ]+\",\"\", description_text)\n",
    "\n",
    "    # Convert everything in lowercase\n",
    "    description_text = description_text.lower()\n",
    "\n",
    "    # Remove stopwords using nltk package\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = nltk.word_tokenize(description_text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Apply stemming using ntlk package\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Separate words with commas\n",
    "    words = ','.join(words)\n",
    "\n",
    "    return words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:48:29.279292Z",
     "end_time": "2023-11-19T14:48:29.296949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Create and fill new column where the preprocessed descriptions wil be stored:\n",
    "data[\"clean_description\"] = data[\"description\"].apply(preprocess_description)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:48:32.207827Z",
     "end_time": "2023-11-19T14:48:41.206535Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1) Preprocessing the fees column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# This function was provided by ChatGPT.\n",
    "# It downloads the latest exchange rates (wrt United States Dollars) from openexchangerates.org.\n",
    "# It returns a dictionary of the form {exchange_code : exchange_rate}\n",
    "def get_latest_exchange_rates(app_id):\n",
    "\n",
    "    base_url = \"https://openexchangerates.org/api/latest.json\"\n",
    "    params = {\"app_id\": app_id}\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"rates\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch exchange rates. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Dictionary provided by ChatGPT, I changed some symbols that were not present.\n",
    "# It will be used to convert a currency symbol into currency code.\n",
    "\n",
    "currency_symbol_to_code = {\n",
    "    '$': 'USD',  # United States Dollar\n",
    "    '€': 'EUR',  # Euro\n",
    "    \"Euro\": \"EUR\", # Euro\n",
    "    '¥': 'JPY',  # Japanese Yen\n",
    "    '£': 'GBP',  # British Pound Sterling\n",
    "    'A$': 'AUD',  # Australian Dollar\n",
    "    'C$': 'CAD',  # Canadian Dollar\n",
    "    'CHF': 'CHF',  # Swiss Franc\n",
    "    'kr': 'SEK',  # Swedish Krona\n",
    "    'NZ$': 'NZD',  # New Zealand Dollar\n",
    "    # Add more symbols and codes as needed\n",
    "}\n",
    "\n",
    "# This function handles the preprocessing of the \"fees\" field\n",
    "def preprocess_fees(fees_text):\n",
    "\n",
    "    # Handles the case of \"nan\"\n",
    "    if type(fees_text) != str:\n",
    "        return None\n",
    "\n",
    "    # Preallocate all the fees found in text\n",
    "    total_fees = []\n",
    "\n",
    "    # Symbols we are looking for\n",
    "    symbols = \"GBP|USD|ISK|£|\\$|₹|¥|₪|₽|₩|₦|₴|﷼|€|Euro\"\n",
    "\n",
    "    # Match the (symbol, number) case\n",
    "    left_symbol_matches = re.findall(fr'(?:{symbols})+\\s*[0-9]+[,.]?[0-9]*', fees_text)\n",
    "\n",
    "    # Match the (number,  symbol) case\n",
    "    right_symbol_matches = re.findall(fr'[0-9]+[,.]?[0-9]*\\s*(?:{symbols})+', fees_text)\n",
    "\n",
    "    # Merge them\n",
    "    matches = left_symbol_matches + right_symbol_matches\n",
    "\n",
    "    # If we got no matches returns None\n",
    "    if len(matches) == 0 :\n",
    "        return None\n",
    "\n",
    "    for match in matches:\n",
    "        # Remove \",\" or \".\" and change to the right type\n",
    "        number = re.findall('([0-9]+)[.,]*([0-9]*)', match)[0]\n",
    "        number = float(number[0] + number[1])\n",
    "\n",
    "        # Isolate symbol\n",
    "        symbol = re.findall(fr'(?i)({symbols})', match)[0]\n",
    "\n",
    "        # Transform symbol into code (if not already a code)\n",
    "        if symbol in currency_symbol_to_code.keys():\n",
    "            symbol = currency_symbol_to_code[symbol]\n",
    "\n",
    "        # Change into USD using the exchange_rates dictionary and append to fees\n",
    "        total_fees.append(number * exchange_rates[symbol])\n",
    "\n",
    "    # Take the max fee and return it\n",
    "    max_fee = round(max(total_fees))\n",
    "    return max_fee\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:48:41.208945Z",
     "end_time": "2023-11-19T14:48:41.222928Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Load latest exchange rates\n",
    "my_app_id = \"1457fcd3d536441baad3ce7918b5025b\"\n",
    "exchange_rates = get_latest_exchange_rates(my_app_id)\n",
    "\n",
    "# Save preprocessed fees into a new column\n",
    "data[\"fees_USD\"] = data[\"fees\"].apply(preprocess_fees)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T14:48:47.954252Z",
     "end_time": "2023-11-19T14:48:48.672317Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Conjunctive query\n",
    "\n",
    "### 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Store all terms contained in the \"clean_description\" as a set\n",
    "terms_set = set(','.join(data[\"clean_description\"]).split(\",\"))\n",
    "\n",
    "# Create a dict that associate each term to a unique id\n",
    "terms_id_dict = {key: value for value, key in enumerate(terms_set)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T15:07:06.812370Z",
     "end_time": "2023-11-19T15:07:06.881520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-19T15:07:07.697976Z",
     "end_time": "2023-11-19T15:07:07.935772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we create the inverted index dictionary.\n",
    "\n",
    "# Preallocate a dictionary with the form: {term_id : []}\n",
    "inverted = {i : [] for i in range(len(terms_id_dict))}\n",
    "\n",
    "# Iterating over all terms and texts in the \"clean_description\" field\n",
    "for i,text in enumerate(data[\"clean_description\"]):\n",
    "    text_list = text.split(\",\")\n",
    "    for term in text_list:\n",
    "\n",
    "        # Get term id\n",
    "        term_id = terms_id_dict[term]\n",
    "\n",
    "        # Add document id \"i\" to the term_id list\n",
    "        inverted[term_id].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# This function takes a query as a input and returns the most affine docs:\n",
    "\n",
    "def naive_search_engine(query):\n",
    "    # Apply same preprocessing done for descriptions and split wrt \",\"\n",
    "    query = preprocess_description(query).split(\",\")\n",
    "\n",
    "    # For each term in query get all the docs ids that contain it as a set\n",
    "    query_docs = [set(inverted[terms_id_dict[term]]) for term in query]\n",
    "\n",
    "    # Select the docs ids that contain all the query term, and sort them\n",
    "    query_docs = set.intersection(*query_docs)\n",
    "    query_docs = list(sorted(query_docs))\n",
    "\n",
    "    # Return selected columns of those docs\n",
    "    result  = data.iloc[query_docs, [0,1,4,12]]\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T15:07:08.970848Z",
     "end_time": "2023-11-19T15:07:08.990071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             courseName  \\\n1                          Accounting and Finance - MSc   \n4                                        Addictions MSc   \n12                            Analytical Toxicology MSc   \n48                                Civil Engineering MSc   \n86                                      Economics - MSc   \n...                                                 ...   \n5909  Master of Science/Postgraduate Diploma in Envi...   \n5937  Master Sociology – Social and Economic Psychology   \n5957                               Masters in Economics   \n5963           Master's in Global and European Politics   \n5965                  Masters in Hospitality Management   \n\n                                         universityName  \\\n1                                   University of Leeds   \n4                                 King’s College London   \n12                                King’s College London   \n48                              University of Greenwich   \n86                                  University of Leeds   \n...                                                 ...   \n5909  The Hong Kong University of Science and Techno...   \n5937                              University of Cologne   \n5957                               University of Lisbon   \n5963  European School of Political and Social Scienc...   \n5965                        Ecole hotelière de Lausanne   \n\n                                            description  \\\n1     Businesses and governments rely on sound finan...   \n4     Join us for an online session for prospective ...   \n12    The Analytical Toxicology MSc is a unique stud...   \n48    Meet the future demands of the construction in...   \n86    Our MSc Economics allows you to apply economic...   \n...                                                 ...   \n5909  The program is meant to meet the needs of prac...   \n5937  This programme provides you with:a solid found...   \n5957  OBJECTIVESThe MSc in Economics aims to provide...   \n5963  Europe and the EU in a changing worldOur inter...   \n5965  With our Master in Hospitality Management, you...   \n\n                                                    url  \n1     https://www.findamasters.com/masters-degrees/c...  \n4     https://www.findamasters.com/masters-degrees/c...  \n12    https://www.findamasters.com/masters-degrees/c...  \n48    https://www.findamasters.com/masters-degrees/c...  \n86    https://www.findamasters.com/masters-degrees/c...  \n...                                                 ...  \n5909  https://www.findamasters.com/masters-degrees/c...  \n5937  https://www.findamasters.com/masters-degrees/c...  \n5957  https://www.findamasters.com/masters-degrees/c...  \n5963  https://www.findamasters.com/masters-degrees/c...  \n5965  https://www.findamasters.com/masters-degrees/c...  \n\n[463 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>courseName</th>\n      <th>universityName</th>\n      <th>description</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Accounting and Finance - MSc</td>\n      <td>University of Leeds</td>\n      <td>Businesses and governments rely on sound finan...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Addictions MSc</td>\n      <td>King’s College London</td>\n      <td>Join us for an online session for prospective ...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Analytical Toxicology MSc</td>\n      <td>King’s College London</td>\n      <td>The Analytical Toxicology MSc is a unique stud...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Civil Engineering MSc</td>\n      <td>University of Greenwich</td>\n      <td>Meet the future demands of the construction in...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>Economics - MSc</td>\n      <td>University of Leeds</td>\n      <td>Our MSc Economics allows you to apply economic...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5909</th>\n      <td>Master of Science/Postgraduate Diploma in Envi...</td>\n      <td>The Hong Kong University of Science and Techno...</td>\n      <td>The program is meant to meet the needs of prac...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5937</th>\n      <td>Master Sociology – Social and Economic Psychology</td>\n      <td>University of Cologne</td>\n      <td>This programme provides you with:a solid found...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5957</th>\n      <td>Masters in Economics</td>\n      <td>University of Lisbon</td>\n      <td>OBJECTIVESThe MSc in Economics aims to provide...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5963</th>\n      <td>Master's in Global and European Politics</td>\n      <td>European School of Political and Social Scienc...</td>\n      <td>Europe and the EU in a changing worldOur inter...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5965</th>\n      <td>Masters in Hospitality Management</td>\n      <td>Ecole hotelière de Lausanne</td>\n      <td>With our Master in Hospitality Management, you...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n  </tbody>\n</table>\n<p>463 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_search_engine(\"advanced knowledge\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T15:07:10.796653Z",
     "end_time": "2023-11-19T15:07:10.833795Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2) Conjunctive query & Ranking score\n",
    "\n",
    "\n",
    "For the second search engine, given a query, we want to get the top-k (the choice of k it's up to you!) documents related to the query. In particular:\n",
    "\n",
    "Find all the documents that contain all the words in the query.\n",
    "Sort them by their similarity with the query.\n",
    "Return in output k documents, or all the documents with non-zero similarity with the query when the results are less than k. You must use a heap data structure (you can use Python libraries) for maintaining the top-k documents.\n",
    "To solve this task, you must use the tfIdf score and the Cosine similarity. The field to consider is still the description. Let's see how.\n",
    "\n",
    "### 2.2.1) Inverted index\n",
    "\n",
    "Your second Inverted Index must be of this format:\n",
    "\n",
    "{\n",
    "term_id_1:[(document1, tfIdf_{term,document1}), (document2, tfIdf_{term,document2}), (document4, tfIdf_{term,document4}), ...],\n",
    "term_id_2:[(document1, tfIdf_{term,document1}), (document3, tfIdf_{term,document3}), (document5, tfIdf_{term,document5}), (document6, tfIdf_{term,document6}), ...],\n",
    "...}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Here we create the second inverted index dictionary.\n",
    "\n",
    "# Preallocate a dictionary with the form: {term_id : []}\n",
    "inverted_with_scores = {i : [] for i in range(len(terms_id_dict))}\n",
    "\n",
    "# Iterating over all terms and texts in the \"clean_description\" field\n",
    "for i,text in enumerate(data[\"clean_description\"]):\n",
    "    text_list = text.split(\",\")\n",
    "\n",
    "    # Set here has the purpose of selecting unique terms only.\n",
    "    # We don't want to insert in inverted_2 dict multiple times the same score\n",
    "    for term in set(text_list):\n",
    "\n",
    "        # Get term id\n",
    "        term_id = terms_id_dict[term]\n",
    "\n",
    "        # Get idf score: total number of documents / number of documents term is in\n",
    "        term_idf = len(data[\"clean_description\"]) / len(inverted[term_id])\n",
    "\n",
    "        # Get tf score: number of times term appears in text / total number of terms in text\n",
    "        term_tf =  sum([word == term for word in text_list]) / len(text_list)\n",
    "\n",
    "        # Compute tfidf score\n",
    "        term_tfidf = term_tf * term_idf\n",
    "\n",
    "        # Update new_inverted list\n",
    "        inverted_with_scores[term_id].append((i , term_tfidf))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T15:07:13.582667Z",
     "end_time": "2023-11-19T15:07:16.007074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Here we define our second search engine\n",
    "\n",
    "# This function computes from scratch cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "\n",
    "    # Calculate the norms\n",
    "    norm_vec_1 = np.linalg.norm(vec1)\n",
    "    norm_vec_2 = np.linalg.norm(vec2)\n",
    "\n",
    "    # Compute the cosine similarity\n",
    "    cos_sim = np.dot(vec1, vec2) / (norm_vec_1 * norm_vec_2)\n",
    "\n",
    "    return cos_sim\n",
    "\n",
    "\n",
    "def  top_k_search_engine(query, k):\n",
    "\n",
    "    # Apply same preprocessing done for descriptions and split wrt \",\"\n",
    "    query = preprocess_description(query).split(\",\")\n",
    "\n",
    "    # Get query terms ids\n",
    "    query_ids = [terms_id_dict[term] for term in query]\n",
    "\n",
    "    # Calculate for each term in query its tfidf score\n",
    "    query_idf = np.array([len(data[\"clean_description\"]) / len(inverted[term_id]) for term_id in query_ids])\n",
    "    query_tf =  np.array([sum([word == term for word in query]) / len(query) for term in query]) # change this\n",
    "    query_tfidf = query_idf * query_tf\n",
    "\n",
    "    # Get the indexes of docs that contain all terms in query using inverted_1\n",
    "    docs_ids = [set(inverted[term_id]) for term_id in query_ids]\n",
    "    appropriate_docs_ids = list(set.intersection(*docs_ids))\n",
    "\n",
    "    # docs_tfidf will contain, for each id in appropriate_docs_ids, its tfidf vectorial representation.\n",
    "    docs_tfidf = {i : [] for i in appropriate_docs_ids}\n",
    "\n",
    "    # For each term in the query we retrieve its inverted_2 list of tuples\n",
    "    for term_id in query_ids:\n",
    "        list_of_tuples = inverted_with_scores[term_id]\n",
    "        for tuple_doc in list_of_tuples:\n",
    "\n",
    "            # When we encounter a tuple with an appropriate doc id  we add its tfidf score in docs_tfidf\n",
    "            if tuple_doc[0] in appropriate_docs_ids:\n",
    "                docs_tfidf[tuple_doc[0]].append(tuple_doc[1])\n",
    "\n",
    "    # Transform into a list\n",
    "    docs_tfidf = list(docs_tfidf.values())\n",
    "\n",
    "    # Compute cosine similarities between query_tfidf and each doc_tfidf\n",
    "    cos_sims = [cosine_similarity(query_tfidf, doc_tfidf) for doc_tfidf in docs_tfidf]\n",
    "\n",
    "    # Select all appropriate_docs_ids from data and specified columns\n",
    "    result  = data.iloc[appropriate_docs_ids, [0,1,4,12]]\n",
    "\n",
    "    # Add the cosine similarity score and sort the dataframe\n",
    "    result[\"cos_sim\"] = cos_sims\n",
    "    result = result.sort_values(by='cos_sim', ascending=False)\n",
    "\n",
    "    # Get, if possible, just the top k\n",
    "    if k < result.shape[0]:\n",
    "        result = result[:k]\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T15:07:16.380756Z",
     "end_time": "2023-11-19T15:07:16.401037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             courseName  \\\n3993  Geo-information Science and Earth Observation MSc   \n2041                   Clinical Ophthalmic Practice MSc   \n5120  LSE-Peking University Double Degree MSc Enviro...   \n2436       Countering Extremist Crime and Terrorism MSc   \n4897              International Money and Banking - MSc   \n1496            Biomaterials and Tissue Engineering MSc   \n764             Advanced Design and Manufacturing - MSc   \n3981  Geographical Information Systems and Environme...   \n2818                         Diagnostic Radiography MSc   \n5576                       Master of Chemistry (Leuven)   \n\n                                        universityName  \\\n3993                              University of Twente   \n2041                         University College London   \n5120  London School of Economics and Political Science   \n2436                         University College London   \n4897                          University of Birmingham   \n1496                         University College London   \n764                          University of Northampton   \n3981                            University of Brighton   \n2818                           University College Cork   \n5576                                         KU Leuven   \n\n                                            description  \\\n3993  INTERESTED IN A CAREER IN SPATIAL DATA SCIENCE...   \n2041  Register your interest in graduate study at UC...   \n5120  Ask LSEOrganised jointly by LSE and Peking Uni...   \n2436  Register your interest in graduate study at UC...   \n4897  The correlation between macroeconomics, bankin...   \n1496  Register your interest in graduate study at UC...   \n764   Our Advanced Design and Manufacturing MSc addr...   \n3981  Environmental issues are a global concern. Our...   \n2818  Our MSc Diagnostic Radiography programme is an...   \n5576  Breakthroughs in chemistry can change the text...   \n\n                                                    url  cos_sim  \n3993  https://www.findamasters.com/masters-degrees/c...      1.0  \n2041  https://www.findamasters.com/masters-degrees/c...      1.0  \n5120  https://www.findamasters.com/masters-degrees/c...      1.0  \n2436  https://www.findamasters.com/masters-degrees/c...      1.0  \n4897  https://www.findamasters.com/masters-degrees/c...      1.0  \n1496  https://www.findamasters.com/masters-degrees/c...      1.0  \n764   https://www.findamasters.com/masters-degrees/c...      1.0  \n3981  https://www.findamasters.com/masters-degrees/c...      1.0  \n2818  https://www.findamasters.com/masters-degrees/c...      1.0  \n5576  https://www.findamasters.com/masters-degrees/c...      1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>courseName</th>\n      <th>universityName</th>\n      <th>description</th>\n      <th>url</th>\n      <th>cos_sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3993</th>\n      <td>Geo-information Science and Earth Observation MSc</td>\n      <td>University of Twente</td>\n      <td>INTERESTED IN A CAREER IN SPATIAL DATA SCIENCE...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2041</th>\n      <td>Clinical Ophthalmic Practice MSc</td>\n      <td>University College London</td>\n      <td>Register your interest in graduate study at UC...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5120</th>\n      <td>LSE-Peking University Double Degree MSc Enviro...</td>\n      <td>London School of Economics and Political Science</td>\n      <td>Ask LSEOrganised jointly by LSE and Peking Uni...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2436</th>\n      <td>Countering Extremist Crime and Terrorism MSc</td>\n      <td>University College London</td>\n      <td>Register your interest in graduate study at UC...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4897</th>\n      <td>International Money and Banking - MSc</td>\n      <td>University of Birmingham</td>\n      <td>The correlation between macroeconomics, bankin...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>Biomaterials and Tissue Engineering MSc</td>\n      <td>University College London</td>\n      <td>Register your interest in graduate study at UC...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>Advanced Design and Manufacturing - MSc</td>\n      <td>University of Northampton</td>\n      <td>Our Advanced Design and Manufacturing MSc addr...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3981</th>\n      <td>Geographical Information Systems and Environme...</td>\n      <td>University of Brighton</td>\n      <td>Environmental issues are a global concern. Our...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2818</th>\n      <td>Diagnostic Radiography MSc</td>\n      <td>University College Cork</td>\n      <td>Our MSc Diagnostic Radiography programme is an...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5576</th>\n      <td>Master of Chemistry (Leuven)</td>\n      <td>KU Leuven</td>\n      <td>Breakthroughs in chemistry can change the text...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_search_engine(\"advanced knowledge\", k = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-19T15:07:26.694195Z",
     "end_time": "2023-11-19T15:07:26.758789Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
