{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T21:40:37.243769Z",
     "end_time": "2023-11-21T21:40:42.902119Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data collection\n",
    "\n",
    "## 1.1. Get the list of master's degree courses\n",
    "We created a file named 'urls.txt' that contains all the urls associated with the url of each master page.\n",
    "for reaching such purpose, we iterate over all 400 pages and took the link for every 15 urls of each page.\n",
    "we stored all urls in 'urls.txt' file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:29:57.119032Z",
     "end_time": "2023-11-18T16:31:44.436742Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open(\"urls.txt\",\"w\") # First we create a txt file where we can write the URLs  #  w means writing mode\n",
    "for i in range(1, 401): #from first page to page 400\n",
    "    url = f\"https://www.findamasters.com/masters-degrees/msc-degrees/?PG={i}\" #pages can be scrolled by changing the number after PG\n",
    "    result = requests.get(url) # as we have done in class\n",
    "    soup = BeautifulSoup(result.text, 'html.parser') # to get the html of each page\n",
    "\n",
    "    for link in soup.find_all(class_ = re.compile('courseLink')): #as in class to get each tag of the page which belongs to class courseLink\n",
    "        c = (link.get(\"href\"))  # url of each page in the i-th page\n",
    "        f.write(\"https://www.findamasters.com/\"+c) #writing the rows\n",
    "        f.write(\"\\n\")\n",
    "f.close()\n",
    "print('The \"urls.txt\" file is generated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl master's degree pages\n",
    "\n",
    "We wrote a function named 'download_url'.\n",
    "Since the FindMaster website blocks us for 70 seconds for every (20 to 22) requests we send, we use 'time.sleep(70)' to wait and then resend the http get request. \n",
    "we also omit to download the http files that their directory are already existed.\n",
    "\n",
    "for sending http get requests asynchronously, we can use async and await methods and take the advantage of using \"aiohttp\" library. the other way is to use ThreadPoolExecutor function executer. \n",
    "It means that we store the executer command in a variable named 'future_to_url' that we are able to call in the future.\n",
    "The ThreadPoolExecutor is a built-in Python module that provides managing a pool of worker threads. It allows us to submit tasks to the pool, which are then executed by one of the worker threads in the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Function to download and save HTML for a given URL\n",
    "def download_url(url, folder_path, page_number):\n",
    "    # Create a folder for each page if it doesn't exist\n",
    "    page_folder = os.path.join(folder_path, f\"page_{page_number}\")\n",
    "    if os.path.exists(page_folder):\n",
    "        # uncomment the below code to see which pages are skiped, cause they have already been downloaded.\n",
    "        # print(f\"Skipping Page: {page_number} - Folder already exists.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url) # Send a GET request to the URL\n",
    "        response.raise_for_status()  # Raise an exception for bad responses \n",
    "\n",
    "        # Create a folder for each page if it doesn't exist\n",
    "        os.makedirs(page_folder, exist_ok=True)\n",
    "\n",
    "        # Save the HTML content to a file\n",
    "        file_path = os.path.join(page_folder, f\"html_{page_number}.html\")\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"Downloaded page {page_number}: {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download page {page_number}: {url}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Retrying in 70 seconds...\")\n",
    "        time.sleep(70)  # Wait for 10 seconds before retrying\n",
    "        download_url(url, folder_path, page_number)  # Retry the download\n",
    "\n",
    "# Read all URLs one by one\n",
    "with open('urls.txt', 'r') as urls_file:\n",
    "    urls = urls_file.read().splitlines()\n",
    "\n",
    "output_folder = 'HTML_folders' # Store all HTML files into this directory.\n",
    "\n",
    "# We can use ThreadPoolExecutor for sending http requests asynchronously. \n",
    "# However, Since the FindMaster website blocks us for 70 seconds for every (20 to 22) requests we send, \n",
    "# the max_workers in below code assigned to number 1. So it sends requests synchronously.\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    # Enumerate through each URL and submit download tasks to the executor\n",
    "    future_to_url = {executor.submit(download_url, url, output_folder, page_number): url for page_number, url in enumerate(urls, start=1)}\n",
    "\n",
    "print(\"All HTML files are stored in the HTML_folders directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages\n",
    "Here we create a '.tsv' file including the following columns for each of the HTML files.\n",
    "\n",
    "1. Course Name (to save as ```courseName```): string;\n",
    "2. University (to save as ```universityName```): string;\n",
    "3. Faculty (to save as ```facultyName```): string\n",
    "4. Full or Part Time (to save as ```isItFullTime```): string;\n",
    "5. Short Description (to save as ```description```): string;\n",
    "6. Start Date (to save as ```startDate```): string;\n",
    "7. Fees (to save as ```fees```): string;\n",
    "8. Modality (to save as ```modality```):string;\n",
    "9. Duration (to save as ```duration```):string;\n",
    "10. City (to save as ```city```): string;\n",
    "11. Country (to save as ```country```): string;\n",
    "12. Presence or online modality (to save as ```administration```): string;\n",
    "13. Link to the page (to save as ```url```): string.\n",
    "\n",
    "Then, we merge all those files together to generate our final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "# '/Users/armanfeili/Arman/Sapienza Courses/ADM/Homeworks/HW3/phase-2/ADM-HW3/HTML_folders'\n",
    "\n",
    "for i in range(1,6001):\n",
    "    # os.chdir(r'C:\\Users\\susan\\Documents\\DS\\ADM\\HW3\\ADM-HW3\\HTML_folders\\page_'+str(i)) #change directories\n",
    "    os.chdir(r'/Users/armanfeili/Arman/Sapienza Courses/ADM/Homeworks/HW3/phase-3/ADM-HW3/HTML_folders/page_'+str(i)) #change directories\n",
    "    \n",
    "    for filename in os.listdir(os.getcwd()): # get all the files in a folder\n",
    "        if filename.endswith(\".tsv\"): continue # tsv file is already generated.\n",
    "        elif filename.endswith(\".html\"): # if file extension is .html\n",
    "            with open(os.path.join(os.getcwd(), filename), 'r',encoding='utf-8') as f: # open each file into a folder\n",
    "                soup = BeautifulSoup(f,'html.parser') # get the html file by each file \n",
    "                out=[] # initialize a list where we append all the informations parsed from each html file\n",
    "\n",
    "                # 1  Course Name\n",
    "                courseName = soup.find_all(class_=re.compile(\"course-header__course-title\"))\n",
    "                out.append(courseName[0].text.strip() if courseName else \"\") #text.strip to eliminate strange simbols for the space\n",
    "                # 2  University\n",
    "                universityName = soup.find_all(class_=re.compile(\"course-header__institution\"))\n",
    "                out.append(universityName[0].text if universityName else \"\")\n",
    "                # 3  Faculty\n",
    "                facultyName = soup.find_all(class_=re.compile(\"course-header__department\"))\n",
    "                out.append(facultyName[0].text if facultyName else \"\")\n",
    "                # 4  Full or Part Time\n",
    "                isItFullTime = soup.find_all(class_=re.compile(\"concealLink\"))\n",
    "                out.append(isItFullTime[0].text if isItFullTime else \"\")\n",
    "                # 5  Short Description\n",
    "                description = soup.find_all(class_=re.compile(\"course-sections__content\"))\n",
    "                out.append(description[0].text.replace('\\n', '') if description else \"\")\n",
    "                # 6  Start Date\n",
    "                startDate = soup.find_all(class_=re.compile(\"key-info__start-date\"))\n",
    "                out.append(startDate[0].text if startDate else \"\")\n",
    "                # 7  Fees \n",
    "                fees_elements = soup.find_all(class_=re.compile(\"course-sections__fees\")) # taking the fee\n",
    "                fees_text = fees_elements[0].text.replace('\\n', '') if fees_elements else \"\" \n",
    "                cleaned_fees = re.sub(r'Fees', '', fees_text)  # To not \"Fees\" at the beginning \n",
    "                out.append(cleaned_fees.strip() if cleaned_fees else \"\")\n",
    "                # 8  Modality\n",
    "                modality = soup.find_all(class_=re.compile(\"key-info__qualification\"))\n",
    "                out.append(modality[0].text if modality else \"\")\n",
    "                # 9  Duration\n",
    "                duration = soup.find_all(class_=re.compile(\"key-info__duration\"))\n",
    "                out.append(duration[0].text if duration else \"\")\n",
    "                # 10  City\n",
    "                city = soup.find_all(class_=re.compile(\"course-data__city\"))\n",
    "                out.append(city[0].text if city else \"\")\n",
    "                # 11  Country\n",
    "                country = soup.find_all(class_=re.compile(\"course-data__country\"))\n",
    "                out.append(country[0].text if country else \"\")\n",
    "                # 12  Presence or online modality\n",
    "                # We have seen that some courses has both online or oncampus modality, one of them is \"Master of Business Administration\"\n",
    "                on_campus_elements = soup.find_all(class_=re.compile(\"course-data__on-campus\"))\n",
    "                online_elements = soup.find_all(class_=re.compile(\"course-data__online\"))\n",
    "                if on_campus_elements and online_elements:\n",
    "                    out.append(\"both\")\n",
    "                else:\n",
    "                    out.append(on_campus_elements[0].text if on_campus_elements else online_elements[0].text if online_elements else \"Nan\")\n",
    "                # 13  Link to the page\n",
    "                out.append(soup.find('link', {'rel': 'canonical'}).get('href') if soup.find('link', {'rel': 'canonical'}) else \"Nan\")\n",
    "                f.close()\n",
    "                \n",
    "                # Creating file .tsv\n",
    "                l = ['courseName','universityName','facultyName','isItFullTime','description','startDate','fees','modality','duration',\n",
    "                    'city','country','administration','url']\n",
    "                with open(filename+'.tsv','w',encoding='utf-8') as tsv:\n",
    "                    tsv_output = csv.writer(tsv, delimiter='\\t')\n",
    "                    tsv_output.writerow(l)\n",
    "                    tsv_output.writerow(out)\n",
    "    os.chdir('..')  \n",
    "\n",
    "print(\"All HTML files have been read and all .tsv files have been generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "# to merge all the .tsv files\n",
    "for i in range(1,6001):\n",
    "    # os.chdir(r'./HTML_folders/page_'+str(i)) #change directories\n",
    "    os.chdir(r'/Users/armanfeili/Arman/Sapienza Courses/ADM/Homeworks/HW3/phase-3/ADM-HW3/HTML_folders/page_'+str(i)) #change directories\n",
    "    for filename in os.listdir(os.getcwd()):\n",
    "        if filename.endswith(\".tsv\"):\n",
    "            a = pd.read_csv(filename,sep='\\t')\n",
    "            data.append(a)\n",
    "    os.chdir('..')\n",
    "data=pd.concat(data,ignore_index=True)   \n",
    "data.to_csv('../dataset.tsv',sep='\\t',index=False) # Saving the big one\n",
    "print(\"dataset.tsv file has been generated as the main dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# An illustration to the dataset:\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "courseName         24\nuniversityName     24\nfacultyName        24\nisItFullTime       24\ndescription        24\nstartDate          24\nfees              146\nmodality           24\nduration           24\ncity               24\ncountry            24\nadministration      0\nurl                 0\ndtype: int64"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset we are going to work with\n",
    "data = pd.read_table(r\"dataset.tsv\")\n",
    "\n",
    "# Count and show NAs\n",
    "np.sum(data.isna())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T22:56:08.246778Z",
     "end_time": "2023-11-21T22:56:08.357869Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             courseName  \\\n0              3D Design for Virtual Environments - MSc   \n1                          Accounting and Finance - MSc   \n2     Accounting, Accountability & Financial Managem...   \n3     Accounting, Financial Management and Digital B...   \n4                                        Addictions MSc   \n...                                                 ...   \n5995              Materials and Molecular Modelling MSc   \n5996                          Materials Chemistry - MSc   \n5997                            Materials Chemistry MSc   \n5998                              Materials Engineering   \n5999                          Materials Engineering MSc   \n\n                     universityName  \\\n0     Glasgow Caledonian University   \n1               University of Leeds   \n2             King’s College London   \n3             University of Reading   \n4             King’s College London   \n...                             ...   \n5995      University College London   \n5996         University of Bradford   \n5997        University of Edinburgh   \n5998            University of Padua   \n5999             Swansea University   \n\n                                            facultyName isItFullTime  \\\n0           School of Engineering and Built Environment    Full time   \n1                      Leeds University Business School    Full time   \n2                                King’s Business School    Full time   \n3                                Henley Business School    Full time   \n4     Institute of Psychiatry, Psychology and Neuros...    Full time   \n...                                                 ...          ...   \n5995                            Department of Chemistry    Full time   \n5996                           Faculty of Life Sciences    Full time   \n5997                                School of Chemistry    Full time   \n5998                              School of Engineering    Full time   \n5999         School of Engineering and Applied Sciences    Full time   \n\n                                            description  startDate  \\\n0     3D visualisation and animation play a role in ...  September   \n1     Businesses and governments rely on sound finan...  September   \n2     Our Accounting, Accountability & Financial Man...  September   \n3     Embark on a professional accounting career wit...  September   \n4     Join us for an online session for prospective ...  September   \n...                                                 ...        ...   \n5995  Register your interest in graduate study at UC...  September   \n5996  We provide a unique Master’s education in Mate...  September   \n5997  Programme descriptionMaterials Chemistry has e...  September   \n5998  The Master's degree Materials Engineering is a...    October   \n5999  The MSc in Materials Engineering provides you ...  September   \n\n                                                   fees modality  \\\n0     Please see the university website for further ...      MSc   \n1     UK: £18,000 (Total) International: £34,750 (To...      MSc   \n2     Please see the university website for further ...      MSc   \n3     Please see the university website for further ...      MSc   \n4     Please see the university website for further ...      MSc   \n...                                                 ...      ...   \n5995                                Full time - £14,100      MSc   \n5996  Please see the university website for further ...      MSc   \n5997  Tuition fees vary between degree programmes. F...      MSc   \n5998  Our tuition fees will not exceed 2700 euros pe...      MSc   \n5999  Please visit our website for the Materials Eng...      MSc   \n\n                                               duration       city  \\\n0                                      1 year full-time    Glasgow   \n1                                      1 year full time      Leeds   \n2                                             1 year FT     London   \n3                                      1 year full time    Reading   \n4                                           One year FT     London   \n...                                                 ...        ...   \n5995                                   1 year full time     London   \n5996                                   1 year full time   Bradford   \n5997                                   1 year full-time  Edinburgh   \n5998                                            2 years      Padua   \n5999  1 year full-time; 2 years part-time; 3 years p...    Swansea   \n\n             country administration  \\\n0     United Kingdom      On Campus   \n1     United Kingdom      On Campus   \n2     United Kingdom      On Campus   \n3     United Kingdom      On Campus   \n4     United Kingdom      On Campus   \n...              ...            ...   \n5995  United Kingdom      On Campus   \n5996  United Kingdom      On Campus   \n5997  United Kingdom      On Campus   \n5998           Italy      On Campus   \n5999  United Kingdom      On Campus   \n\n                                                    url  \n0     https://www.findamasters.com/masters-degrees/c...  \n1     https://www.findamasters.com/masters-degrees/c...  \n2     https://www.findamasters.com/masters-degrees/c...  \n3     https://www.findamasters.com/masters-degrees/c...  \n4     https://www.findamasters.com/masters-degrees/c...  \n...                                                 ...  \n5995  https://www.findamasters.com/masters-degrees/c...  \n5996  https://www.findamasters.com/masters-degrees/c...  \n5997  https://www.findamasters.com/masters-degrees/c...  \n5998  https://www.findamasters.com/masters-degrees/c...  \n5999  https://www.findamasters.com/masters-degrees/c...  \n\n[5854 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>courseName</th>\n      <th>universityName</th>\n      <th>facultyName</th>\n      <th>isItFullTime</th>\n      <th>description</th>\n      <th>startDate</th>\n      <th>fees</th>\n      <th>modality</th>\n      <th>duration</th>\n      <th>city</th>\n      <th>country</th>\n      <th>administration</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3D Design for Virtual Environments - MSc</td>\n      <td>Glasgow Caledonian University</td>\n      <td>School of Engineering and Built Environment</td>\n      <td>Full time</td>\n      <td>3D visualisation and animation play a role in ...</td>\n      <td>September</td>\n      <td>Please see the university website for further ...</td>\n      <td>MSc</td>\n      <td>1 year full-time</td>\n      <td>Glasgow</td>\n      <td>United Kingdom</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Accounting and Finance - MSc</td>\n      <td>University of Leeds</td>\n      <td>Leeds University Business School</td>\n      <td>Full time</td>\n      <td>Businesses and governments rely on sound finan...</td>\n      <td>September</td>\n      <td>UK: £18,000 (Total) International: £34,750 (To...</td>\n      <td>MSc</td>\n      <td>1 year full time</td>\n      <td>Leeds</td>\n      <td>United Kingdom</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Accounting, Accountability &amp; Financial Managem...</td>\n      <td>King’s College London</td>\n      <td>King’s Business School</td>\n      <td>Full time</td>\n      <td>Our Accounting, Accountability &amp; Financial Man...</td>\n      <td>September</td>\n      <td>Please see the university website for further ...</td>\n      <td>MSc</td>\n      <td>1 year FT</td>\n      <td>London</td>\n      <td>United Kingdom</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Accounting, Financial Management and Digital B...</td>\n      <td>University of Reading</td>\n      <td>Henley Business School</td>\n      <td>Full time</td>\n      <td>Embark on a professional accounting career wit...</td>\n      <td>September</td>\n      <td>Please see the university website for further ...</td>\n      <td>MSc</td>\n      <td>1 year full time</td>\n      <td>Reading</td>\n      <td>United Kingdom</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Addictions MSc</td>\n      <td>King’s College London</td>\n      <td>Institute of Psychiatry, Psychology and Neuros...</td>\n      <td>Full time</td>\n      <td>Join us for an online session for prospective ...</td>\n      <td>September</td>\n      <td>Please see the university website for further ...</td>\n      <td>MSc</td>\n      <td>One year FT</td>\n      <td>London</td>\n      <td>United Kingdom</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5995</th>\n      <td>Materials and Molecular Modelling MSc</td>\n      <td>University College London</td>\n      <td>Department of Chemistry</td>\n      <td>Full time</td>\n      <td>Register your interest in graduate study at UC...</td>\n      <td>September</td>\n      <td>Full time - £14,100</td>\n      <td>MSc</td>\n      <td>1 year full time</td>\n      <td>London</td>\n      <td>United Kingdom</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5996</th>\n      <td>Materials Chemistry - MSc</td>\n      <td>University of Bradford</td>\n      <td>Faculty of Life Sciences</td>\n      <td>Full time</td>\n      <td>We provide a unique Master’s education in Mate...</td>\n      <td>September</td>\n      <td>Please see the university website for further ...</td>\n      <td>MSc</td>\n      <td>1 year full time</td>\n      <td>Bradford</td>\n      <td>United Kingdom</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5997</th>\n      <td>Materials Chemistry MSc</td>\n      <td>University of Edinburgh</td>\n      <td>School of Chemistry</td>\n      <td>Full time</td>\n      <td>Programme descriptionMaterials Chemistry has e...</td>\n      <td>September</td>\n      <td>Tuition fees vary between degree programmes. F...</td>\n      <td>MSc</td>\n      <td>1 year full-time</td>\n      <td>Edinburgh</td>\n      <td>United Kingdom</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5998</th>\n      <td>Materials Engineering</td>\n      <td>University of Padua</td>\n      <td>School of Engineering</td>\n      <td>Full time</td>\n      <td>The Master's degree Materials Engineering is a...</td>\n      <td>October</td>\n      <td>Our tuition fees will not exceed 2700 euros pe...</td>\n      <td>MSc</td>\n      <td>2 years</td>\n      <td>Padua</td>\n      <td>Italy</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5999</th>\n      <td>Materials Engineering MSc</td>\n      <td>Swansea University</td>\n      <td>School of Engineering and Applied Sciences</td>\n      <td>Full time</td>\n      <td>The MSc in Materials Engineering provides you ...</td>\n      <td>September</td>\n      <td>Please visit our website for the Materials Eng...</td>\n      <td>MSc</td>\n      <td>1 year full-time; 2 years part-time; 3 years p...</td>\n      <td>Swansea</td>\n      <td>United Kingdom</td>\n      <td>On Campus</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5854 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NAs\n",
    "data = data.dropna()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T22:56:10.346562Z",
     "end_time": "2023-11-21T22:56:10.404737Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.0 Preprocessing\n",
    "\n",
    "### 2.0.0) Preprocessing the text\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "# This function takes a text, removes special cases, punctuations and stop-words then\n",
    "# it applies stemming and finally returns the preprocessed words separated by commas.\n",
    "\n",
    "def preprocess_description(description_text):\n",
    "\n",
    "    # Handle the cases of float type (there are 24)\n",
    "    if type(description_text) != str:\n",
    "        return \"\"\n",
    "\n",
    "    # Remove all special chars and punctuations\n",
    "    description_text = re.sub(\"[^a-z A-Z ]+\",\"\", description_text)\n",
    "\n",
    "    # Convert everything in lowercase\n",
    "    description_text = description_text.lower()\n",
    "\n",
    "    # Remove stopwords using nltk package\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = nltk.word_tokenize(description_text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Apply stemming using ntlk package\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Separate words with commas\n",
    "    words = ','.join(words)\n",
    "\n",
    "    return words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:13:10.258369Z",
     "end_time": "2023-11-21T23:13:10.278772Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "# Create and fill new column where the preprocessed descriptions wil be stored:\n",
    "data[\"clean_description\"] = data[\"description\"].apply(preprocess_description)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:13:12.769529Z",
     "end_time": "2023-11-21T23:13:23.340576Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         description  \\\n0  3D visualisation and animation play a role in ...   \n1  Businesses and governments rely on sound finan...   \n2  Our Accounting, Accountability & Financial Man...   \n3  Embark on a professional accounting career wit...   \n4  Join us for an online session for prospective ...   \n5  The Advanced Chemical Engineering MSc at Leeds...   \n6  Programme overviewThe Advanced Master in Finan...   \n7  Programme overviewThe Advanced Master in Innov...   \n8  Progress your career as a physiotherapist with...   \n9  Goal of the pro­grammeWould you like to be inv...   \n\n                                   clean_description  \n0  visualis,anim,play,role,mani,area,popular,medi...  \n1  busi,govern,reli,sound,financi,knowledg,underp...  \n2  account,account,financi,manag,msc,cours,provid...  \n3  embark,profession,account,career,academ,ground...  \n4  join,us,onlin,session,prospect,student,find,ms...  \n5  advanc,chemic,engin,msc,leed,build,core,founda...  \n6  programm,overviewth,advanc,master,financi,mark...  \n7  programm,overviewth,advanc,master,innov,strate...  \n8  progress,career,physiotherapist,within,nh,priv...  \n9  goal,programmewould,like,involv,find,solut,fut...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>description</th>\n      <th>clean_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3D visualisation and animation play a role in ...</td>\n      <td>visualis,anim,play,role,mani,area,popular,medi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Businesses and governments rely on sound finan...</td>\n      <td>busi,govern,reli,sound,financi,knowledg,underp...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Our Accounting, Accountability &amp; Financial Man...</td>\n      <td>account,account,financi,manag,msc,cours,provid...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Embark on a professional accounting career wit...</td>\n      <td>embark,profession,account,career,academ,ground...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Join us for an online session for prospective ...</td>\n      <td>join,us,onlin,session,prospect,student,find,ms...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The Advanced Chemical Engineering MSc at Leeds...</td>\n      <td>advanc,chemic,engin,msc,leed,build,core,founda...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Programme overviewThe Advanced Master in Finan...</td>\n      <td>programm,overviewth,advanc,master,financi,mark...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Programme overviewThe Advanced Master in Innov...</td>\n      <td>programm,overviewth,advanc,master,innov,strate...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Progress your career as a physiotherapist with...</td>\n      <td>progress,career,physiotherapist,within,nh,priv...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Goal of the pro­grammeWould you like to be inv...</td>\n      <td>goal,programmewould,like,involv,find,solut,fut...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show different fields\n",
    "data[[\"description\", \"clean_description\"]].head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:13:25.847631Z",
     "end_time": "2023-11-21T23:13:25.882281Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1) Preprocessing the fees column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "# This function was provided by ChatGPT.\n",
    "# It downloads the latest exchange rates (wrt United States Dollars) from openexchangerates.org.\n",
    "# It returns a dictionary of the form {exchange_code : exchange_rate}\n",
    "def get_latest_exchange_rates(app_id):\n",
    "\n",
    "    base_url = \"https://openexchangerates.org/api/latest.json\"\n",
    "    params = {\"app_id\": app_id}\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"rates\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch exchange rates. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Dictionary provided by ChatGPT, I changed some symbols that were not present.\n",
    "# It will be used to convert a currency symbol into currency code.\n",
    "\n",
    "currency_symbol_to_code = {\n",
    "    '$': 'USD',  # United States Dollar\n",
    "    '€': 'EUR',  # Euro\n",
    "    \"EURO\": \"EUR\", # Euro\n",
    "    '¥': 'JPY',  # Japanese Yen\n",
    "    '£': 'GBP',  # British Pound Sterling\n",
    "    'A$': 'AUD',  # Australian Dollar\n",
    "    'C$': 'CAD',  # Canadian Dollar\n",
    "    'CHF': 'CHF',  # Swiss Franc\n",
    "    'KR': 'SEK',  # Swedish Krona\n",
    "    'NZ$': 'NZD',  # New Zealand Dollar\n",
    "    # Add more symbols and codes as needed\n",
    "}\n",
    "\n",
    "# This function handles the preprocessing of the \"fees\" field\n",
    "def preprocess_fees(fees_text):\n",
    "\n",
    "    # Handles the case of \"nan\"\n",
    "    if type(fees_text) != str:\n",
    "        return None\n",
    "\n",
    "    # Preallocate all the fees found in text\n",
    "    total_fees = []\n",
    "\n",
    "    # Symbols we are looking for\n",
    "    symbols = \"GBP|USD|ISK|£|\\$|₹|¥|₪|₽|₩|₦|₴|﷼|€|Euro\"\n",
    "\n",
    "    # Match the (symbol, number) case\n",
    "    left_symbol_matches = re.findall(fr'(?:{symbols})+\\s*[0-9]+[,.]?[0-9]*', fees_text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Match the (number,  symbol) case\n",
    "    right_symbol_matches = re.findall(fr'[0-9]+[,.]?[0-9]*\\s*(?:{symbols})+', fees_text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Merge them\n",
    "    matches = left_symbol_matches + right_symbol_matches\n",
    "\n",
    "    # If we got no matches returns None\n",
    "    if len(matches) == 0 :\n",
    "        return None\n",
    "\n",
    "    for match in matches:\n",
    "        # Remove \",\" or \".\" and change to the right type\n",
    "        number = re.findall('([0-9]+)[.,]*([0-9]*)', match)[0]\n",
    "        number = float(number[0] + number[1])\n",
    "\n",
    "        # Isolate symbol and upper case it (to match exchange_rates_dict codes)\n",
    "        symbol = re.findall(fr'(?i)({symbols})', match)[0].upper()\n",
    "\n",
    "        # Transform symbol into code (if not already a code)\n",
    "        if symbol in currency_symbol_to_code.keys():\n",
    "            symbol = currency_symbol_to_code[symbol]\n",
    "\n",
    "        # Change into USD using the exchange_rates dictionary and append to fees\n",
    "        total_fees.append(number / exchange_rates_dict[symbol])\n",
    "\n",
    "    # Take the max fee and return it\n",
    "    max_fee = round(max(total_fees))\n",
    "    return max_fee\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:13:30.239273Z",
     "end_time": "2023-11-21T23:13:30.244497Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "AED: 3.67281\n",
      "AFN: 70.205771\n",
      "ALL: 94.659415\n",
      "AMD: 402.028287\n",
      "ANG: 1.801361\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load latest exchange rates\n",
    "my_app_id = \"1457fcd3d536441baad3ce7918b5025b\"\n",
    "exchange_rates_dict = get_latest_exchange_rates(my_app_id)\n",
    "\n",
    "# Show exchange_rates_dict\n",
    "count = 0\n",
    "print(\"{\")\n",
    "for key, value in exchange_rates_dict.items():\n",
    "    if count < 5:\n",
    "        print(f'{key}: {value}')\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "print(\"}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:13:33.308652Z",
     "end_time": "2023-11-21T23:13:33.884673Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "{'AED': 3.67281,\n 'AFN': 70.205771,\n 'ALL': 94.659415,\n 'AMD': 402.028287,\n 'ANG': 1.801361,\n 'AOA': 829.905333,\n 'ARS': 355.966893,\n 'AUD': 1.52512,\n 'AWG': 1.768,\n 'AZN': 1.7,\n 'BAM': 1.786984,\n 'BBD': 2,\n 'BDT': 110.692829,\n 'BGN': 1.791948,\n 'BHD': 0.376747,\n 'BIF': 2845.177181,\n 'BMD': 1,\n 'BND': 1.336464,\n 'BOB': 6.906665,\n 'BRL': 4.899224,\n 'BSD': 1,\n 'BTC': 2.7156302e-05,\n 'BTN': 83.285679,\n 'BWP': 13.41654,\n 'BYN': 3.292918,\n 'BZD': 2.014674,\n 'CAD': 1.370147,\n 'CDF': 2575.361714,\n 'CHF': 0.883671,\n 'CLF': 0.031526,\n 'CLP': 869.936087,\n 'CNH': 7.142968,\n 'CNY': 7.099033,\n 'COP': 4057.225474,\n 'CRC': 530.494682,\n 'CUC': 1,\n 'CUP': 25.75,\n 'CVE': 100.988416,\n 'CZK': 22.474885,\n 'DJF': 178.062377,\n 'DKK': 6.832836,\n 'DOP': 56.882573,\n 'DZD': 134.093675,\n 'EGP': 30.902213,\n 'ERN': 15,\n 'ETB': 55.801723,\n 'EUR': 0.916482,\n 'FJD': 2.24175,\n 'FKP': 0.797519,\n 'GBP': 0.797519,\n 'GEL': 2.705,\n 'GGP': 0.797519,\n 'GHS': 11.95637,\n 'GIP': 0.797519,\n 'GMD': 67.25,\n 'GNF': 8613.139488,\n 'GTQ': 7.825849,\n 'GYD': 209.118715,\n 'HKD': 7.795942,\n 'HNL': 24.712088,\n 'HRK': 6.904941,\n 'HTG': 132.484199,\n 'HUF': 349.15608,\n 'IDR': 15512.029714,\n 'ILS': 3.715306,\n 'IMP': 0.797519,\n 'INR': 83.338208,\n 'IQD': 1309.586518,\n 'IRR': 42262.5,\n 'ISK': 140.33,\n 'JEP': 0.797519,\n 'JMD': 155.502086,\n 'JOD': 0.7094,\n 'JPY': 148.39158943,\n 'KES': 152.37188,\n 'KGS': 89.01,\n 'KHR': 4111.651027,\n 'KMF': 450.949793,\n 'KPW': 900,\n 'KRW': 1295.720848,\n 'KWD': 0.308108,\n 'KYD': 0.832915,\n 'KZT': 458.633021,\n 'LAK': 20682.973031,\n 'LBP': 15027.556711,\n 'LKR': 328.442103,\n 'LRD': 187.999989,\n 'LSL': 18.371265,\n 'LYD': 4.817811,\n 'MAD': 10.126379,\n 'MDL': 17.724482,\n 'MGA': 4517.70745,\n 'MKD': 56.295621,\n 'MMK': 2098.941457,\n 'MNT': 3450,\n 'MOP': 8.025858,\n 'MRU': 39.885,\n 'MUR': 44.140681,\n 'MVR': 15.4,\n 'MWK': 1683.146,\n 'MXN': 17.194912,\n 'MYR': 4.653,\n 'MZN': 63.850001,\n 'NAD': 18.62,\n 'NGN': 818.669412,\n 'NIO': 36.65035,\n 'NOK': 10.67976,\n 'NPR': 133.256292,\n 'NZD': 1.653106,\n 'OMR': 0.384944,\n 'PAB': 1,\n 'PEN': 3.736613,\n 'PGK': 3.727581,\n 'PHP': 55.354091,\n 'PKR': 285.51708,\n 'PLN': 4.008496,\n 'PYG': 7438.471964,\n 'QAR': 3.6405,\n 'RON': 4.553182,\n 'RSD': 107.077389,\n 'RUB': 88.226885,\n 'RWF': 1235.605457,\n 'SAR': 3.750536,\n 'SBD': 8.468008,\n 'SCR': 13.329723,\n 'SDG': 601,\n 'SEK': 10.466474,\n 'SGD': 1.338453,\n 'SHP': 0.797519,\n 'SLL': 20969.5,\n 'SOS': 571.146313,\n 'SRD': 37.9665,\n 'SSP': 130.26,\n 'STD': 22281.8,\n 'STN': 22.608421,\n 'SVC': 8.745785,\n 'SYP': 2512.53,\n 'SZL': 18.365054,\n 'THB': 35.184388,\n 'TJS': 10.914748,\n 'TMT': 3.5,\n 'TND': 3.10375,\n 'TOP': 2.373521,\n 'TRY': 28.785979,\n 'TTD': 6.791539,\n 'TWD': 31.375483,\n 'TZS': 2500.889903,\n 'UAH': 36.093669,\n 'UGX': 3785.425953,\n 'USD': 1,\n 'UYU': 39.498168,\n 'UZS': 12268.779487,\n 'VES': 35.40681,\n 'VND': 24140.718639,\n 'VUV': 118.722,\n 'WST': 2.8,\n 'XAF': 601.173006,\n 'XAG': 0.04211354,\n 'XAU': 0.00050037,\n 'XCD': 2.70255,\n 'XDR': 0.750774,\n 'XOF': 601.173006,\n 'XPD': 0.00091975,\n 'XPF': 109.365434,\n 'XPT': 0.00106625,\n 'YER': 250.299958,\n 'ZAR': 18.71046,\n 'ZMW': 23.28841,\n 'ZWL': 322}"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange_rates_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:13:36.168170Z",
     "end_time": "2023-11-21T23:13:36.189287Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "# Save preprocessed fees into a new column\n",
    "data[\"fees_USD\"] = data[\"fees\"].apply(preprocess_fees)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:13:50.063518Z",
     "end_time": "2023-11-21T23:13:50.178762Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Conjunctive query\n",
    "\n",
    "### 2.1.1) Create your index!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "# Store all terms contained in the \"clean_description\" as a set\n",
    "terms_set = set(','.join(data[\"clean_description\"]).split(\",\"))\n",
    "\n",
    "# Create a dict that associate each term to a unique id\n",
    "terms_id_dict = {key: value for value, key in enumerate(terms_set)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:13:54.695492Z",
     "end_time": "2023-11-21T23:13:54.712649Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T23:14:09.187933Z",
     "end_time": "2023-11-21T23:14:09.347923Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we create the inverted index dictionary.\n",
    "\n",
    "# Preallocate a dictionary with the form: {term_id : []}\n",
    "inverted_index_dict = {i : [] for i in range(len(terms_id_dict))}\n",
    "\n",
    "# Iterating over all terms and texts in the \"clean_description\" field\n",
    "for i,text in enumerate(data[\"clean_description\"]):\n",
    "    text_list = text.split(\",\")\n",
    "    for term in text_list:\n",
    "\n",
    "        # Get term id\n",
    "        term_id = terms_id_dict[term]\n",
    "\n",
    "        # Add document id \"i\" to the term_id list\n",
    "        inverted_index_dict[term_id].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "0: [1576, 2307, 4459]\n",
      "1: [3177]\n",
      "2: [55, 178, 194, 194, 223, 320, 325, 396, 737, 1272, 1299, 1304, 1570, 1911, 1912, 2068, 2085, 2164, 2437, 2460, 2465, 2623, 2708, 2859, 2860, 2900, 2947, 3130, 3380, 3617, 3710, 3829, 3906, 4144, 4150, 4210, 4397, 4514, 4661, 4691, 4695, 4797, 4839, 4986, 5054, 5082, 5385, 5388, 5630, 5633, 5638, 5760]\n",
      "3: [4361]\n",
      "4: [5153]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Show inverted_index_dict structure\n",
    "print(\"{\")\n",
    "count = 0\n",
    "for key, value in inverted_index_dict.items():\n",
    "    if count < 5:\n",
    "        print(f'{key}: {value}')\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "print(\"}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:14:11.363480Z",
     "end_time": "2023-11-21T23:14:11.395493Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "# This function takes a query as a input and returns the most affine docs:\n",
    "\n",
    "def naive_search_engine(query):\n",
    "    # Apply same preprocessing done for descriptions and split wrt \",\"\n",
    "    query = preprocess_description(query).split(\",\")\n",
    "\n",
    "    # For each term in query get all the docs ids that contain it as a set\n",
    "    query_docs = [set(inverted_index_dict[terms_id_dict[term]]) for term in query]\n",
    "\n",
    "    # Select the docs ids that contain all the query term, and sort them\n",
    "    query_docs = set.intersection(*query_docs)\n",
    "    query_docs = list(sorted(query_docs))\n",
    "\n",
    "    # Return selected columns of those docs\n",
    "    result  = data.iloc[query_docs, [0,1,4,12]]\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:14:14.139574Z",
     "end_time": "2023-11-21T23:14:14.174982Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             courseName  \\\n1                          Accounting and Finance - MSc   \n4                                        Addictions MSc   \n12                            Analytical Toxicology MSc   \n48                                Civil Engineering MSc   \n86                                      Economics - MSc   \n...                                                 ...   \n5909  Master of Science/Postgraduate Diploma in Envi...   \n5937  Master Sociology – Social and Economic Psychology   \n5957                               Masters in Economics   \n5963           Master's in Global and European Politics   \n5965                  Masters in Hospitality Management   \n\n                                         universityName  \\\n1                                   University of Leeds   \n4                                 King’s College London   \n12                                King’s College London   \n48                              University of Greenwich   \n86                                  University of Leeds   \n...                                                 ...   \n5909  The Hong Kong University of Science and Techno...   \n5937                              University of Cologne   \n5957                               University of Lisbon   \n5963  European School of Political and Social Scienc...   \n5965                        Ecole hotelière de Lausanne   \n\n                                            description  \\\n1     Businesses and governments rely on sound finan...   \n4     Join us for an online session for prospective ...   \n12    The Analytical Toxicology MSc is a unique stud...   \n48    Meet the future demands of the construction in...   \n86    Our MSc Economics allows you to apply economic...   \n...                                                 ...   \n5909  The program is meant to meet the needs of prac...   \n5937  This programme provides you with:a solid found...   \n5957  OBJECTIVESThe MSc in Economics aims to provide...   \n5963  Europe and the EU in a changing worldOur inter...   \n5965  With our Master in Hospitality Management, you...   \n\n                                                    url  \n1     https://www.findamasters.com/masters-degrees/c...  \n4     https://www.findamasters.com/masters-degrees/c...  \n12    https://www.findamasters.com/masters-degrees/c...  \n48    https://www.findamasters.com/masters-degrees/c...  \n86    https://www.findamasters.com/masters-degrees/c...  \n...                                                 ...  \n5909  https://www.findamasters.com/masters-degrees/c...  \n5937  https://www.findamasters.com/masters-degrees/c...  \n5957  https://www.findamasters.com/masters-degrees/c...  \n5963  https://www.findamasters.com/masters-degrees/c...  \n5965  https://www.findamasters.com/masters-degrees/c...  \n\n[455 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>courseName</th>\n      <th>universityName</th>\n      <th>description</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Accounting and Finance - MSc</td>\n      <td>University of Leeds</td>\n      <td>Businesses and governments rely on sound finan...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Addictions MSc</td>\n      <td>King’s College London</td>\n      <td>Join us for an online session for prospective ...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Analytical Toxicology MSc</td>\n      <td>King’s College London</td>\n      <td>The Analytical Toxicology MSc is a unique stud...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Civil Engineering MSc</td>\n      <td>University of Greenwich</td>\n      <td>Meet the future demands of the construction in...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>Economics - MSc</td>\n      <td>University of Leeds</td>\n      <td>Our MSc Economics allows you to apply economic...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5909</th>\n      <td>Master of Science/Postgraduate Diploma in Envi...</td>\n      <td>The Hong Kong University of Science and Techno...</td>\n      <td>The program is meant to meet the needs of prac...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5937</th>\n      <td>Master Sociology – Social and Economic Psychology</td>\n      <td>University of Cologne</td>\n      <td>This programme provides you with:a solid found...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5957</th>\n      <td>Masters in Economics</td>\n      <td>University of Lisbon</td>\n      <td>OBJECTIVESThe MSc in Economics aims to provide...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5963</th>\n      <td>Master's in Global and European Politics</td>\n      <td>European School of Political and Social Scienc...</td>\n      <td>Europe and the EU in a changing worldOur inter...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n    <tr>\n      <th>5965</th>\n      <td>Masters in Hospitality Management</td>\n      <td>Ecole hotelière de Lausanne</td>\n      <td>With our Master in Hospitality Management, you...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n    </tr>\n  </tbody>\n</table>\n<p>455 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_search_engine(\"advanced knowledge\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:14:17.897555Z",
     "end_time": "2023-11-21T23:14:17.991823Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2) Conjunctive query & Ranking score\n",
    "\n",
    "### 2.2.1) Inverted index\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "# Here we create the second inverted index dictionary.\n",
    "\n",
    "# Preallocate a dictionary with the form: {term_id : []}\n",
    "inverted_index_dict_with_scores = {i : [] for i in range(len(terms_id_dict))}\n",
    "\n",
    "# Iterating over all terms and texts in the \"clean_description\" field\n",
    "for i,text in enumerate(data[\"clean_description\"]):\n",
    "    text_list = text.split(\",\")\n",
    "\n",
    "    # Set here has the purpose of selecting unique terms only.\n",
    "    # We don't want to insert in inverted_2 dict multiple times the same score\n",
    "    for term in set(text_list):\n",
    "\n",
    "        # Get term id\n",
    "        term_id = terms_id_dict[term]\n",
    "\n",
    "        # Get idf score: total number of documents / number of documents term is in\n",
    "        term_idf = np.log(len(data[\"clean_description\"]) / len(inverted_index_dict[term_id]))\n",
    "\n",
    "        # Get tf score: number of times term appears in text / total number of terms in text\n",
    "        term_tf =  sum([word == term for word in text_list]) / len(text_list)\n",
    "\n",
    "        # Compute tfidf score\n",
    "        term_tfidf = term_tf * term_idf\n",
    "\n",
    "        # Update new_inverted list\n",
    "        inverted_index_dict_with_scores[term_id].append((i , term_tfidf))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:14:19.605368Z",
     "end_time": "2023-11-21T23:14:22.225494Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "0: [(1576, 0.10980098809541626), (2307, 0.11479194209975337), (4459, 0.12025822505688447)]\n",
      "1: [(3177, 0.1807266764010798)]\n",
      "2: [(55, 0.05429467527207361), (178, 0.08747475460500748), (194, 0.13496104996201153), (223, 0.08287082015211235), (320, 0.1968181978612668), (325, 0.07872727914450672), (396, 0.07743666801099024), (737, 0.08144201290811041), (1272, 0.10496970552600898), (1299, 0.10496970552600898), (1304, 0.06845850360391889), (1570, 0.08588430452128007), (1911, 0.08287082015211235), (1912, 0.08287082015211235), (2068, 0.09447273497340808), (2085, 0.08006163980797294), (2164, 0.08747475460500748), (2437, 0.08912522167302649), (2460, 0.1005029095461788), (2465, 0.08006163980797294), (2623, 0.05248485276300449), (2708, 0.1073553806516001), (2859, 0.07267133459492929), (2860, 0.07267133459492929), (2900, 0.04820037498643269), (2947, 0.1005029095461788), (3130, 0.07157025376773339), (3380, 0.0705020410249314), (3617, 0.07872727914450672), (3710, 0.008019756788914098), (3829, 0.15237537898936787), (3906, 0.13121213190751121), (4144, 0.09640074997286538), (4150, 0.1073553806516001), (4210, 0.09640074997286538), (4397, 0.06748052498100576), (4514, 0.06470735272151237), (4661, 0.08747475460500748), (4691, 0.07380682419797506), (4695, 0.07618768949468394), (4797, 0.14761364839595012), (4839, 0.07872727914450672), (4986, 0.1005029095461788), (5054, 0.4723636748670404), (5082, 0.012596364663121076), (5385, 0.09640074997286538), (5388, 0.00899740333080077), (5630, 0.09083916824366162), (5633, 0.07872727914450672), (5638, 0.09262032840530203), (5760, 0.10496970552600898)]\n",
      "3: [(4361, 0.13769651535320368)]\n",
      "4: [(5153, 0.16367698994814778)]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Show inverted_index_dict_with_scores structure\n",
    "print(\"{\")\n",
    "count = 0\n",
    "for key, value in inverted_index_dict_with_scores.items():\n",
    "    if count < 5:\n",
    "        print(f'{key}: {value}')\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "print(\"}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:14:23.333013Z",
     "end_time": "2023-11-21T23:14:23.353267Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2.2) Execute the query\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "# Here we define our second search engine\n",
    "\n",
    "# This function computes from scratch cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "\n",
    "    # Calculate the norms\n",
    "    norm_vec_1 = np.linalg.norm(vec1)\n",
    "    norm_vec_2 = np.linalg.norm(vec2)\n",
    "\n",
    "    # Compute the cosine similarity\n",
    "    cos_sim = np.dot(vec1, vec2) / (norm_vec_1 * norm_vec_2)\n",
    "\n",
    "    return cos_sim\n",
    "\n",
    "\n",
    "def  top_k_search_engine(query, k):\n",
    "\n",
    "    # Apply same preprocessing done for descriptions and split wrt \",\"\n",
    "    query = preprocess_description(query).split(\",\")\n",
    "\n",
    "    # Get query terms ids\n",
    "    query_ids = [terms_id_dict[term] for term in query]\n",
    "\n",
    "    # Calculate for each term in query its tfidf score\n",
    "    query_idf = np.array([np.log(len(data[\"clean_description\"]) / len(inverted_index_dict[term_id])) for term_id in query_ids])\n",
    "    query_tf =  np.array([sum([word == term for word in query]) / len(query) for term in query]) # change this\n",
    "    query_tfidf = query_idf * query_tf\n",
    "\n",
    "    # Get the indexes of docs that contain all terms in query using inverted_1\n",
    "    docs_ids = [set(inverted_index_dict[term_id]) for term_id in query_ids]\n",
    "    appropriate_docs_ids = list(set.intersection(*docs_ids))\n",
    "\n",
    "    # docs_tfidf will contain, for each id in appropriate_docs_ids, its tfidf vectorial representation.\n",
    "    docs_tfidf = {i : [] for i in appropriate_docs_ids}\n",
    "\n",
    "    # For each term in the query we retrieve its inverted_2 list of tuples\n",
    "    for term_id in query_ids:\n",
    "        list_of_tuples = inverted_index_dict_with_scores[term_id]\n",
    "        for tuple_doc in list_of_tuples:\n",
    "\n",
    "            # When we encounter a tuple with an appropriate doc id  we add its tfidf score in docs_tfidf\n",
    "            if tuple_doc[0] in appropriate_docs_ids:\n",
    "                docs_tfidf[tuple_doc[0]].append(tuple_doc[1])\n",
    "\n",
    "    # Transform into a list\n",
    "    docs_tfidf = list(docs_tfidf.values())\n",
    "\n",
    "    # Compute cosine similarities between query_tfidf and each doc_tfidf\n",
    "    cos_sims = [cosine_similarity(query_tfidf, doc_tfidf) for doc_tfidf in docs_tfidf]\n",
    "\n",
    "    # Select all appropriate_docs_ids from data and specified columns\n",
    "    result  = data.iloc[appropriate_docs_ids, [0,1,4,12]]\n",
    "\n",
    "    # Add the cosine similarity score and sort the dataframe\n",
    "    result[\"cos_sim\"] = cos_sims\n",
    "    result = result.sort_values(by='cos_sim', ascending=False)\n",
    "\n",
    "    # Get, if possible, just the top k\n",
    "    if k < result.shape[0]:\n",
    "        result = result[:k]\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:14:25.234864Z",
     "end_time": "2023-11-21T23:14:25.249467Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             courseName  \\\n2703      Data Science with Artificial Intelligence MSc   \n3259       Energy Systems and Data Analytics (ESDA) MSc   \n4632                       International Business - MSc   \n721   Advanced Computational Methods for Aeronautics...   \n1412          Banking Innovation and Risk Analytics MSc   \n2577                                  Dance Science MSc   \n4321             History of International Relations MSc   \n4886  International Master of Science in Fire Safety...   \n1028                            Analytical Sciences MSc   \n3313                         Engineering Management MSc   \n\n                                        universityName  \\\n2703                              University of Exeter   \n3259                         University College London   \n4632                             University of Glasgow   \n721                            Imperial College London   \n1412                           University of Edinburgh   \n2577                          University of Chichester   \n4321  London School of Economics and Political Science   \n4886                           University of Edinburgh   \n1028                            University of Bradford   \n3313                           University of Greenwich   \n\n                                            description  \\\n2703  OverviewDesigned for those interested in learn...   \n3259  Register your interest in graduate study at UC...   \n4632  International Business will provide you with a...   \n721   This programme is suitable for applicants who ...   \n1412  Programme descriptionOur MSc in Banking Innova...   \n2577  This suite of MSc programmes is designed for s...   \n4321  Ask LSEThe MSc History of International Relati...   \n4886  Programme descriptionThe International Master ...   \n1028  Our MSc in Analytical Sciences MSc is a resear...   \n3313  Extend and develop your skills and build a car...   \n\n                                                    url  cos_sim  \n2703  https://www.findamasters.com/masters-degrees/c...      1.0  \n3259  https://www.findamasters.com/masters-degrees/c...      1.0  \n4632  https://www.findamasters.com/masters-degrees/c...      1.0  \n721   https://www.findamasters.com/masters-degrees/c...      1.0  \n1412  https://www.findamasters.com/masters-degrees/c...      1.0  \n2577  https://www.findamasters.com/masters-degrees/c...      1.0  \n4321  https://www.findamasters.com/masters-degrees/c...      1.0  \n4886  https://www.findamasters.com/masters-degrees/c...      1.0  \n1028  https://www.findamasters.com/masters-degrees/c...      1.0  \n3313  https://www.findamasters.com/masters-degrees/c...      1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>courseName</th>\n      <th>universityName</th>\n      <th>description</th>\n      <th>url</th>\n      <th>cos_sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2703</th>\n      <td>Data Science with Artificial Intelligence MSc</td>\n      <td>University of Exeter</td>\n      <td>OverviewDesigned for those interested in learn...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>Energy Systems and Data Analytics (ESDA) MSc</td>\n      <td>University College London</td>\n      <td>Register your interest in graduate study at UC...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4632</th>\n      <td>International Business - MSc</td>\n      <td>University of Glasgow</td>\n      <td>International Business will provide you with a...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>721</th>\n      <td>Advanced Computational Methods for Aeronautics...</td>\n      <td>Imperial College London</td>\n      <td>This programme is suitable for applicants who ...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1412</th>\n      <td>Banking Innovation and Risk Analytics MSc</td>\n      <td>University of Edinburgh</td>\n      <td>Programme descriptionOur MSc in Banking Innova...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2577</th>\n      <td>Dance Science MSc</td>\n      <td>University of Chichester</td>\n      <td>This suite of MSc programmes is designed for s...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4321</th>\n      <td>History of International Relations MSc</td>\n      <td>London School of Economics and Political Science</td>\n      <td>Ask LSEThe MSc History of International Relati...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4886</th>\n      <td>International Master of Science in Fire Safety...</td>\n      <td>University of Edinburgh</td>\n      <td>Programme descriptionThe International Master ...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1028</th>\n      <td>Analytical Sciences MSc</td>\n      <td>University of Bradford</td>\n      <td>Our MSc in Analytical Sciences MSc is a resear...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3313</th>\n      <td>Engineering Management MSc</td>\n      <td>University of Greenwich</td>\n      <td>Extend and develop your skills and build a car...</td>\n      <td>https://www.findamasters.com/masters-degrees/c...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_search_engine(\"advanced knowledge\", k = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:14:28.463744Z",
     "end_time": "2023-11-21T23:14:28.520593Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Define a new score!\n",
    "Now it's your turn: build a new metric to rank MSc degrees.\n",
    "\n",
    "Practically:\n",
    "\n",
    "The user will enter a text query. As a starting point, get the query-related documents by exploiting the search engine of Step 2.1.\n",
    "Once you have the documents, you need to sort them according to your new score. In this step, you won't have any more to take into account just the description field of the documents; you can use also the remaining variables in your dataset (or new possible variables that you can create from the existing ones or scrape again from the original web-pages). You must use a heap data structure (you can use Python libraries) for maintaining the top-k documents.\n",
    "N.B.: You have to define a scoring function, not a filter!\n",
    "\n",
    "The output, must contain:\n",
    "\n",
    "courseName\n",
    "universityName\n",
    "description\n",
    "URL\n",
    "The new similarity score of the documents with respect to the query\n",
    "Are the results you obtain better than with the previous scoring function? Explain and compare results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer\n",
    "\n",
    "To develop our customized search engine, we opted to gather supplementary information for each university.\n",
    "Recognizing that the selection of the \"ideal\" university is influenced by the city in which one resides, we chose to extract scores reflecting the quality of life in each city.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "country_capital_dict = {\n",
    "    'Gibraltar': 'Gibraltar',\n",
    "    'Sweden': 'Stockholm',\n",
    "    'Austria': 'Vienna',\n",
    "    'Spain': 'Madrid',\n",
    "    'Singapore': 'Singapore',\n",
    "    'Finland': 'Helsinki',\n",
    "    'Israel': 'Jerusalem',\n",
    "    'Turkey': 'Ankara',\n",
    "    'Germany': 'Berlin',\n",
    "    'Canada': 'Ottawa',\n",
    "    'New Zealand': 'Wellington',\n",
    "    'Netherlands': 'Amsterdam',\n",
    "    'Japan': 'Tokyo',\n",
    "    'United Kingdom': 'London',\n",
    "    'Switzerland': 'Bern',\n",
    "    'Cyprus': 'Nicosia',\n",
    "    'Iceland': 'Reykjavik',\n",
    "    'Jamaica': 'Kingston',\n",
    "    'Czechia': 'Prague',\n",
    "    'Malaysia': 'Kuala Lumpur',\n",
    "    'USA': 'new-orleans',\n",
    "    'Hong Kong': 'Hong Kong',\n",
    "    'Portugal': 'Lisbon',\n",
    "    'Estonia': 'Tallinn',\n",
    "    'Greece': 'Athens',\n",
    "    'Denmark': 'Copenhagen',\n",
    "    'France': 'Paris',\n",
    "    'Lithuania': 'Vilnius',\n",
    "    'Italy': 'Rome',\n",
    "    'India': 'New Delhi',\n",
    "    'Luxembourg': 'Luxembourg City',\n",
    "    'Australia': 'Canberra',\n",
    "    'Croatia': 'Zagreb',\n",
    "    'China': 'Beijing',\n",
    "    'Belgium': 'Brussels',\n",
    "    'Chile': 'Santiago',\n",
    "    'Kazakhstan': 'Nur-Sultan',\n",
    "    'Kazakstan': 'Nur-Sultan',\n",
    "    'Qatar': 'Doha',\n",
    "    'United Arab Emirates': 'Abu Dhabi',\n",
    "    'Saudi Arabia': 'Riyadh',\n",
    "    'Hungary': 'Budapest',\n",
    "    'Norway': 'Oslo',\n",
    "    'Ireland': 'Dublin',\n",
    "    'Romania': 'Bucharest'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:32:09.362493Z",
     "end_time": "2023-11-21T23:32:09.383407Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function used the [Teleport](https://teleport.org/) API to retrieve, for each city in our Data, three scores:\n",
    "- Education score;\n",
    "- Safety score;\n",
    "- Cost of living score.\n",
    "\n",
    "All of them are normalized in $[0,10]$.\n",
    "When a city was not integrated into the teleport API, our solution was to obtain the scores associated with the capital of the country in which the city is located."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "(4.991999999999999, 4.151999999999999, 2.088)"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores_out_of_ten(data.city.loc[115])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:32:16.019078Z",
     "end_time": "2023-11-21T23:32:16.283740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "\n",
    "def get_scores_out_of_ten(city):\n",
    "    # Handle different data types\n",
    "    city = str(city)\n",
    "\n",
    "    try:\n",
    "        # Try to get URL of the initial city\n",
    "        base_url = f\"https://api.teleport.org/api/urban_areas/slug:{city.lower()}/scores/\"\n",
    "        response = requests.get(base_url)\n",
    "\n",
    "        # If city not found, retrieve URL of capital city\n",
    "        if response.status_code == 404:\n",
    "\n",
    "            # Retrieve the country of the city\n",
    "            country = data[data[\"city\"] == city][\"country\"].iloc[0]\n",
    "\n",
    "            # Retrieve capital city of the country\n",
    "            capital_city = country_capital_dict[country]\n",
    "\n",
    "            base_url = f\"https://api.teleport.org/api/urban_areas/slug:{capital_city.lower()}/scores/\"\n",
    "            response = requests.get(base_url)\n",
    "\n",
    "            # If capital city not found, return error\n",
    "            if response.status_code == 404:\n",
    "                return (\"City not found\", \"City not found\", \"City not found\")\n",
    "\n",
    "        # Retrieve scores from URL\n",
    "        datas = response.json()\n",
    "\n",
    "        # Retrieve all categories scores\n",
    "        categories = datas['categories']\n",
    "        scores = {category[\"name\"] : float(category[\"score_out_of_10\"]) for  category in categories}\n",
    "\n",
    "        # Return Cost of Living, Education and Safety\n",
    "        return (scores[\"Cost of Living\"],\n",
    "                scores[\"Education\"],\n",
    "                scores[\"Safety\"])\n",
    "\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {'error': f'Request to Teleport API failed: {e}'}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:31:14.777931Z",
     "end_time": "2023-11-21T23:31:14.794886Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "# Create three new columns for our new scores (around 10m to run)\n",
    "data[['Cost_of_Living', 'Education', 'Safety']]= data.city.apply(lambda x: pd.Series(get_scores_out_of_ten(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T22:58:37.168465Z",
     "end_time": "2023-11-21T23:11:46.080898Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Hong Kong', 'Israel', 'Kazakstan', 'Malaysia', 'USA', 'United Arab Emirates'}"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO fix the following countries\n",
    "a = [type(i) == str for i in data[\"Cost_of_Living\"]]\n",
    "set(data[a].country)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:32:57.164958Z",
     "end_time": "2023-11-21T23:32:57.182460Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Those scores will affect the importance our custom search engine gives to each university.\n",
    "As an initial and naive approach we decided to keep thinks linear and just compute the new score as shown below:\n",
    "\n",
    "\\begin{equation}\n",
    "$NewScore = \\frac{CosSimilarity \\cdot Education \\cdot Safety }{LivingCost}$\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The following function follows the one already shown previously but orders the result with respect to the new score we just defined."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "def  custom_search_engine(query, k):\n",
    "\n",
    "    # Apply same preprocessing done for descriptions and split wrt \",\"\n",
    "    query = preprocess_description(query).split(\",\")\n",
    "\n",
    "    # Get query terms ids\n",
    "    query_ids = [terms_id_dict[term] for term in query]\n",
    "\n",
    "    # Calculate for each term in query its tfidf score\n",
    "    query_idf = np.array([np.log(len(data[\"clean_description\"]) / len(inverted_index_dict[term_id])) for term_id in query_ids])\n",
    "    query_tf =  np.array([sum([word == term for word in query]) / len(query) for term in query]) # change this\n",
    "    query_tfidf = query_idf * query_tf\n",
    "\n",
    "    # Get the indexes of docs that contain all terms in query using inverted_1\n",
    "    docs_ids = [set(inverted_index_dict[term_id]) for term_id in query_ids]\n",
    "    appropriate_docs_ids = list(set.intersection(*docs_ids))\n",
    "\n",
    "    # docs_tfidf will contain, for each id in appropriate_docs_ids, its tfidf vectorial representation.\n",
    "    docs_tfidf = {i : [] for i in appropriate_docs_ids}\n",
    "\n",
    "    # For each term in the query we retrieve its inverted_2 list of tuples\n",
    "    for term_id in query_ids:\n",
    "        list_of_tuples = inverted_index_dict_with_scores[term_id]\n",
    "        for tuple_doc in list_of_tuples:\n",
    "\n",
    "            # When we encounter a tuple with an appropriate doc id  we add its tfidf score in docs_tfidf\n",
    "            if tuple_doc[0] in appropriate_docs_ids:\n",
    "                docs_tfidf[tuple_doc[0]].append(tuple_doc[1])\n",
    "\n",
    "    # Transform into a list\n",
    "    docs_tfidf = list(docs_tfidf.values())\n",
    "\n",
    "    # Compute cosine similarities between query_tfidf and each doc_tfidf\n",
    "    cos_sims = np.array([cosine_similarity(query_tfidf, doc_tfidf) for doc_tfidf in docs_tfidf])\n",
    "\n",
    "    # Select all appropriate_docs_ids from data and specified columns\n",
    "    result  = data.iloc[appropriate_docs_ids]\n",
    "\n",
    "    # Add the cosine similarity score\n",
    "    result[\"cos_sim\"] = cos_sims\n",
    "\n",
    "    # Compute our custom score\n",
    "    our_score = result[\"cos_sim\"] * result[\"Education\"] * result[\"Safety\"] / result[\"Cost_of_Living\"]\n",
    "\n",
    "    # Add the cosine similarity score and sort the dataframe\n",
    "    result[\"score\"] = our_score\n",
    "    result = result.sort_values(by='score', ascending=False)\n",
    "\n",
    "    # Get, if possible, just the top k\n",
    "    if k < result.shape[0]:\n",
    "        result = result[:k]\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-21T23:18:37.934457Z",
     "end_time": "2023-11-21T23:18:37.966364Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Federico\\AppData\\Local\\Temp\\ipykernel_1812\\570275636.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result[\"cos_sim\"] = cos_sims\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:163\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[1;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(op, a, b, use_numexpr)\u001B[0m\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_numexpr:\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;66;03m# error: \"None\" not callable\u001B[39;00m\n\u001B[1;32m--> 239\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:128\u001B[0m, in \u001B[0;36m_evaluate_numexpr\u001B[1;34m(op, op_str, a, b)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 128\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_evaluate_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:69\u001B[0m, in \u001B[0;36m_evaluate_standard\u001B[1;34m(op, op_str, a, b)\u001B[0m\n\u001B[0;32m     68\u001B[0m     _store_test_result(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: can't multiply sequence by non-int of type 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [167]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mcustom_search_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43madvanced knowledge\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [166]\u001B[0m, in \u001B[0;36mcustom_search_engine\u001B[1;34m(query, k)\u001B[0m\n\u001B[0;32m     40\u001B[0m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcos_sim\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m cos_sims\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Compute our custom score\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m our_score \u001B[38;5;241m=\u001B[39m \u001B[43mresult\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcos_sim\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEducation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m*\u001B[39m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSafety\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m/\u001B[39m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCost_of_Living\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# Add the cosine similarity score and sort the dataframe\u001B[39;00m\n\u001B[0;32m     46\u001B[0m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m our_score\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     66\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[0;32m     68\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[1;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:116\u001B[0m, in \u001B[0;36mOpsMixin.__mul__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__mul__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__mul__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:5639\u001B[0m, in \u001B[0;36mSeries._arith_method\u001B[1;34m(self, other, op)\u001B[0m\n\u001B[0;32m   5637\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_arith_method\u001B[39m(\u001B[38;5;28mself\u001B[39m, other, op):\n\u001B[0;32m   5638\u001B[0m     \u001B[38;5;28mself\u001B[39m, other \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39malign_method_SERIES(\u001B[38;5;28mself\u001B[39m, other)\n\u001B[1;32m-> 5639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIndexOpsMixin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py:1295\u001B[0m, in \u001B[0;36mIndexOpsMixin._arith_method\u001B[1;34m(self, other, op)\u001B[0m\n\u001B[0;32m   1292\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001B[0;32m   1294\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1295\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1297\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(result, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:222\u001B[0m, in \u001B[0;36marithmetic_op\u001B[1;34m(left, right, op)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001B[39;00m\n\u001B[0;32m    220\u001B[0m     _bool_arith_check(op, left, right)\n\u001B[1;32m--> 222\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43m_na_arithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res_values\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:170\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[1;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_cmp \u001B[38;5;129;01mand\u001B[39;00m (is_object_dtype(left\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(right)):\n\u001B[0;32m    166\u001B[0m         \u001B[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001B[39;00m\n\u001B[0;32m    167\u001B[0m         \u001B[38;5;66;03m#  on the non-missing values)\u001B[39;00m\n\u001B[0;32m    168\u001B[0m         \u001B[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001B[39;00m\n\u001B[0;32m    169\u001B[0m         \u001B[38;5;66;03m#  incorrectly, see GH#32047\u001B[39;00m\n\u001B[1;32m--> 170\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43m_masked_arith_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    171\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    172\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:108\u001B[0m, in \u001B[0;36m_masked_arith_op\u001B[1;34m(x, y, op)\u001B[0m\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001B[39;00m\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m--> 108\u001B[0m         result[mask] \u001B[38;5;241m=\u001B[39m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxrav\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myrav\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(y):\n",
      "\u001B[1;31mTypeError\u001B[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "custom_search_engine(\"advanced knowledge\", k = 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
