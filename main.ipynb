{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "\n",
    "For this homework, there is no provided dataset. Instead, you have to build your own. Your search engine will run on text documents. So, here\n",
    "we detail the procedure to follow for the data collection. We strongly suggest you work on different modules when implementing the required functions. For example, you may have a ```crawler.py``` module, a ```parser.py``` module, and a ```engine.py``` module: this is a good practice that improves readability in reporting and efficiency in deploying the code. Be careful; you are likely dealing with exceptions and other possible issues! \n",
    "\n",
    "### 1.1. Get the list of master's degree courses\n",
    "\n",
    "We start with the list of courses to include in your corpus of documents. In particular, we focus on web scrapping the [MSc Degrees](https://www.findamasters.com/masters-degrees/msc-degrees/). Next, we want you to **collect the URL** associated with each site in the list from the previously collected list.\n",
    "The list is long and split into many pages. Therefore, we ask you to retrieve only the URLs of the places listed in **the first 400 pages** (each page has 15 courses, so you will end up with 6000 unique master's degree URLs).\n",
    "\n",
    "The output of this step is a `.txt` file whose single line corresponds to the master's URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"urls.txt\",\"w\") # First I create a txt file where I can write the URLs  #  w means writing mode\n",
    "for i in range(1, 401): #from first page to page 400\n",
    "    url = f\"https://www.findamasters.com/masters-degrees/msc-degrees/?PG={i}\" #pages can be scrolled by changing the number after PG\n",
    "    result = requests.get(url) # as we have done in class\n",
    "    soup = BeautifulSoup(result.text, 'html.parser') # to get the html of each page\n",
    "\n",
    "    for link in soup.find_all(class_ = re.compile('courseLink')): #as in class to get each tag of the page which belongs to class courseLink\n",
    "        c = (link.get(\"href\"))  # url of each page in the i-th page\n",
    "        f.write(\"https://www.findamasters.com/\"+c) #writing the rows\n",
    "        f.write(\"\\n\")\n",
    "f.close()\n",
    "print('The \"urls.txt\" file is generated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl master's degree pages\n",
    "\n",
    "We wrote a function named 'download_url'.\n",
    "Since the FindMaster website blocks us for 70 seconds for every (20 to 22) requests we send, we use 'time.sleep(70)' to wait and then resend the http get request. \n",
    "we also omit to download the http files that their directory are already existed.\n",
    "\n",
    "for sending http get requests asynchronously, we can use async and await methods and take the advantage of using \"aiohttp\" library. the other way is to use ThreadPoolExecutor function executer. \n",
    "It means that we store the executer command in a variable named 'future_to_url' that we are able to call in the future.\n",
    "The ThreadPoolExecutor is a built-in Python module that provides managing a pool of worker threads. It allows us to submit tasks to the pool, which are then executed by one of the worker threads in the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded page 1: https://www.findamasters.com//masters-degrees/course/3d-design-for-virtual-environments-msc/?i93d2645c19223\n",
      "Downloaded page 2: https://www.findamasters.com//masters-degrees/course/accounting-and-finance-msc/?i321d3232c3891\n",
      "Downloaded page 3: https://www.findamasters.com//masters-degrees/course/accounting-accountability-and-financial-management-msc/?i132d7816c25522\n",
      "Downloaded page 4: https://www.findamasters.com//masters-degrees/course/accounting-financial-management-and-digital-business-msc/?i345d4286c351\n",
      "Downloaded page 5: https://www.findamasters.com//masters-degrees/course/addictions-msc/?i132d4318c27100\n",
      "Downloaded page 6: https://www.findamasters.com//masters-degrees/course/advanced-chemical-engineering-msc/?i321d8433c50447\n",
      "Downloaded page 7: https://www.findamasters.com//masters-degrees/course/advanced-master-in-financial-markets/?i1298d6514c28542\n",
      "Downloaded page 8: https://www.findamasters.com//masters-degrees/course/advanced-master-in-innovation-and-strategic-management/?i1298d6514c28544\n",
      "Downloaded page 9: https://www.findamasters.com//masters-degrees/course/advanced-physiotherapy-practice-msc/?i93d2635c71983\n",
      "Downloaded page 10: https://www.findamasters.com//masters-degrees/course/agricultural-sciences-msc-agriculture-and-forestry/?i312d6223c45169\n",
      "Downloaded page 11: https://www.findamasters.com//masters-degrees/course/agricultural-environmental-and-resource-economics-msc-agriculture-and-forestry/?i312d6223c45168\n",
      "Downloaded page 12: https://www.findamasters.com//masters-degrees/course/air-quality-solutions-msc/?i321d1045c71834\n",
      "Downloaded page 13: https://www.findamasters.com//masters-degrees/course/analytical-toxicology-msc/?i132d4846c14767\n",
      "Downloaded page 14: https://www.findamasters.com//masters-degrees/course/applied-computer-science-and-artificial-intelligence-msc/?i285d7565c71206\n",
      "Downloaded page 15: https://www.findamasters.com//masters-degrees/course/applied-economics-banking-and-financial-markets-online-msc/?i280d8352c56675\n",
      "Downloaded page 16: https://www.findamasters.com//masters-degrees/course/applied-linguistics-msc/?i307d4953c55536\n",
      "Downloaded page 17: https://www.findamasters.com//masters-degrees/course/applied-mathematics-msc/?i1114d7105c37541\n",
      "Downloaded page 18: https://www.findamasters.com//masters-degrees/course/applied-neuroscience-online-msc-pg-dip/?i132d8371c59808\n",
      "Downloaded page 19: https://www.findamasters.com//masters-degrees/course/applied-physics-msc/?i1114d7105c37542\n",
      "Downloaded page 20: https://www.findamasters.com//masters-degrees/course/applied-statistical-modelling-and-health-informatics-msc-pgcert-pgdip/?i132d4318c55179\n",
      "Downloaded page 21: https://www.findamasters.com//masters-degrees/course/applied-statistics-online-msc/?i353d6511c65071\n",
      "Downloaded page 22: https://www.findamasters.com//masters-degrees/course/archaeology-msc/?i307d4953c55533\n",
      "Downloaded page 23: https://www.findamasters.com//masters-degrees/course/architecture-msc/?i1454d7693c49344\n",
      "Downloaded page 24: https://www.findamasters.com//masters-degrees/course/artificial-intelligence-msc-pgcert/?i321d8597c64297\n",
      "Downloaded page 25: https://www.findamasters.com//masters-degrees/course/astronomy-msc/?i1114d7105c37545\n",
      "Failed to download page 26: https://www.findamasters.com//masters-degrees/course/astrophysics-msc/?i321d1037c71837\n",
      "Error: 429 Client Error: Too Many Requests for url: https://www.findamasters.com//masters-degrees/course/astrophysics-msc/?i321d1037c71837\n",
      "Retrying in 70 seconds...\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Function to download and save HTML for a given URL\n",
    "def download_url(url, folder_path, page_number):\n",
    "    # Create a folder for each page if it doesn't exist\n",
    "    page_folder = os.path.join(folder_path, f\"page_{page_number}\")\n",
    "    if os.path.exists(page_folder):\n",
    "        # uncomment the below code to see which pages are skiped, cause they have already been downloaded.\n",
    "        print(f\"Skipping Page: {page_number} - Folder already exists.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url) # Send a GET request to the URL\n",
    "        response.raise_for_status()  # Raise an exception for bad responses \n",
    "\n",
    "        # Create a folder for each page if it doesn't exist\n",
    "        os.makedirs(page_folder, exist_ok=True)\n",
    "\n",
    "        # Save the HTML content to a file\n",
    "        file_path = os.path.join(page_folder, f\"html_{page_number}.html\")\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"Downloaded page {page_number}: {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download page {page_number}: {url}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Retrying in 70 seconds...\")\n",
    "        time.sleep(70)  # Wait for 10 seconds before retrying\n",
    "        download_url(url, folder_path, page_number)  # Retry the download\n",
    "\n",
    "# Read all URLs one by one\n",
    "with open('urls.txt', 'r') as urls_file:\n",
    "    urls = urls_file.read().splitlines()\n",
    "\n",
    "output_folder = 'HTML_folders' # Store all HTML files into this directory.\n",
    "\n",
    "# We can use ThreadPoolExecutor for sending http requests asynchronously. \n",
    "# However, Since the FindMaster website blocks us for 70 seconds for every (20 to 22) requests we send, \n",
    "# the max_workers in below code assigned to number 1. So it sends requests synchronously.\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    # Enumerate through each URL and submit download tasks to the executor\n",
    "    future_to_url = {executor.submit(download_url, url, output_folder, page_number): url for page_number, url in enumerate(urls, start=1)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages\n",
    "\n",
    "At this point, you should have all the HTML documents about the master's degree of interest, and you can start to extract specific information. The list of the information we desire for each course and their format is as follows:\n",
    "\n",
    "1. Course Name (to save as ```courseName```): string;\n",
    "2. University (to save as ```universityName```): string;\n",
    "3. Faculty (to save as ```facultyName```): string\n",
    "4. Full or Part Time (to save as ```isItFullTime```): string;\n",
    "5. Short Description (to save as ```description```): string;\n",
    "6. Start Date (to save as ```startDate```): string;\n",
    "7. Fees (to save as ```fees```): string;\n",
    "8. Modality (to save as ```modality```):string;\n",
    "9. Duration (to save as ```duration```):string;\n",
    "10. City (to save as ```city```): string;\n",
    "11. Country (to save as ```country```): string;\n",
    "12. Presence or online modality (to save as ```administration```): string;\n",
    "13. Link to the page (to save as ```url```): string.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,3):   \n",
    "    os.chdir(r'C:\\Users\\susan\\Documents\\DS\\ADM\\HW3\\ADM-HW3\\HTML_folders\\page_'+str(i)) #change directories\n",
    "    for filename in os.listdir(os.getcwd()): # get all the files in a folder\n",
    "        if filename.endswith(\".html\"): # if file extension is .html\n",
    "            with open(os.path.join(os.getcwd(), filename), 'r',encoding='utf-8') as f: ## open each file into a folder\n",
    "                soup = BeautifulSoup(f,'html.parser') # get the html file by each file \n",
    "                out=[] # initialize a list where we append all the informations parsed from each html file\n",
    "\n",
    "                # 1  Course Name\n",
    "                [out.append(i.text.strip()) for i in soup.find_all(class_=re.compile(\"course-header__course-title\"))] #text.strip to eliminate strange simbols for the space\n",
    "                # 2  University\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"course-header__institution\"))] \n",
    "                # 3  Faculty\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"course-header__department\"))]\n",
    "                # 4  Full or Part Time\n",
    "                a = [i.text for i in soup.find_all(class_=re.compile(\"concealLink\"))]\n",
    "                out.append(a[0])\n",
    "                # 5  Short Description\n",
    "                b = [i.text.replace('\\n','') for i in soup.find_all(class_=re.compile(\"course-sections__content\"))]\n",
    "                out.append(b[0])\n",
    "                # 6  Start Date\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"key-info__start-date\"))]\n",
    "                # 7  Fees\n",
    "                [out.append(i.text.replace('\\n','')) for i in soup.find_all(class_=re.compile(\"course-sections__fees\"))]\n",
    "                # 8  Modality\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"key-info__duration\"))]\n",
    "                # 9  Duration\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"key-info__duration\"))]\n",
    "                # 10  City\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"course-data__city\"))]\n",
    "                # 11  Country\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"course-data__country\"))]\n",
    "                # 12  Presence or online modality\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"course-data__on-campus\"))]\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"course-data__online\"))]\n",
    "                # 13  Link to the page\n",
    "                link_element = soup.find(class_=re.compile(\"logoLink\"))  # Adjust the class as needed\n",
    "                if link_element:\n",
    "                    link = link_element.get('href')  # Extract the 'href' attribute\n",
    "                    www_index = link.find(\"www.\")\n",
    "                    if www_index != -1:\n",
    "                        www_part = link[www_index:]\n",
    "                        out.append(www_part)\n",
    "                f.close()\n",
    "                \n",
    "                ## Creating file .tsv\n",
    "                l = ['courseName','universityName','facultyName','isItFullTime','description','startDate','fees','modality','duration',\n",
    "                    'city','country','administration','url']\n",
    "                with open(filename+'.tsv','w',encoding='utf-8') as tsv:\n",
    "                    tsv_output = csv.writer(tsv, delimiter='\\t')\n",
    "                    tsv_output.writerow(l)\n",
    "                    tsv_output.writerow(out)\n",
    "    os.chdir('..')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(1,3):\n",
    "    os.chdir(r'C:\\Users\\susan\\Documents\\DS\\ADM\\HW3\\ADM-HW3\\HTML_folders\\page_'+str(i))\n",
    "    for filename in os.listdir(os.getcwd()):\n",
    "        if filename.endswith(\".tsv\"):\n",
    "            a = pd.read_csv(filename,sep='\\t')\n",
    "            data.append(a)\n",
    "    os.chdir('..')\n",
    "data=pd.concat(data,ignore_index=True)     \n",
    "data.to_csv('Dataset.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Design for Virtual Environments - MSc</td>\n",
       "      <td>Glasgow Caledonian University</td>\n",
       "      <td>School of Engineering and Built Environment</td>\n",
       "      <td>Full time</td>\n",
       "      <td>3D visualisation and animation play a role in ...</td>\n",
       "      <td>September</td>\n",
       "      <td>FeesPlease see the university website for furt...</td>\n",
       "      <td>1 year full-time</td>\n",
       "      <td>1 year full-time</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>www.gcu.ac.uk%2fstudy%2fcourses%2fpostgraduate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting and Finance - MSc</td>\n",
       "      <td>University of Leeds</td>\n",
       "      <td>Leeds University Business School</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Businesses and governments rely on sound finan...</td>\n",
       "      <td>September</td>\n",
       "      <td>FeesUK: £18,000 (Total) International: £34,750...</td>\n",
       "      <td>1 year full time</td>\n",
       "      <td>1 year full time</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 courseName                 universityName  \\\n",
       "0  3D Design for Virtual Environments - MSc  Glasgow Caledonian University   \n",
       "1              Accounting and Finance - MSc            University of Leeds   \n",
       "\n",
       "                                   facultyName isItFullTime  \\\n",
       "0  School of Engineering and Built Environment    Full time   \n",
       "1             Leeds University Business School    Full time   \n",
       "\n",
       "                                         description  startDate  \\\n",
       "0  3D visualisation and animation play a role in ...  September   \n",
       "1  Businesses and governments rely on sound finan...  September   \n",
       "\n",
       "                                                fees          modality  \\\n",
       "0  FeesPlease see the university website for furt...  1 year full-time   \n",
       "1  FeesUK: £18,000 (Total) International: £34,750...  1 year full time   \n",
       "\n",
       "           duration     city         country administration  \\\n",
       "0  1 year full-time  Glasgow  United Kingdom      On Campus   \n",
       "1  1 year full time    Leeds  United Kingdom      On Campus   \n",
       "\n",
       "                                                 url  \n",
       "0  www.gcu.ac.uk%2fstudy%2fcourses%2fpostgraduate...  \n",
       "1                                                NaN  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
