{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "\n",
    "For this homework, there is no provided dataset. Instead, you have to build your own. Your search engine will run on text documents. So, here\n",
    "we detail the procedure to follow for the data collection. We strongly suggest you work on different modules when implementing the required functions. For example, you may have a ```crawler.py``` module, a ```parser.py``` module, and a ```engine.py``` module: this is a good practice that improves readability in reporting and efficiency in deploying the code. Be careful; you are likely dealing with exceptions and other possible issues! \n",
    "\n",
    "### 1.1. Get the list of master's degree courses\n",
    "\n",
    "We start with the list of courses to include in your corpus of documents. In particular, we focus on web scrapping the [MSc Degrees](https://www.findamasters.com/masters-degrees/msc-degrees/). Next, we want you to **collect the URL** associated with each site in the list from the previously collected list.\n",
    "The list is long and split into many pages. Therefore, we ask you to retrieve only the URLs of the places listed in **the first 400 pages** (each page has 15 courses, so you will end up with 6000 unique master's degree URLs).\n",
    "\n",
    "The output of this step is a `.txt` file whose single line corresponds to the master's URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"urls.txt\",\"w\") # First I create a txt file where I can write the URLs  #  w means writing mode\n",
    "for i in range(1, 401): #from first page to page 400\n",
    "    url = f\"https://www.findamasters.com/masters-degrees/msc-degrees/?PG={i}\" #pages can be scrolled by changing the number after PG\n",
    "    result = requests.get(url) # as we have done in class\n",
    "    soup = BeautifulSoup(result.text, 'html.parser') # to get the html of each page\n",
    "\n",
    "    for link in soup.find_all(class_ = re.compile('courseLink')): #as in class to get each tag of the page which belongs to class courseLink\n",
    "        c = (link.get(\"href\"))  # url of each page in the i-th page\n",
    "        f.write(\"https://www.findamasters.com/\"+c) #writing the rows\n",
    "        f.write(\"\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
