{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "\n",
    "For this homework, there is no provided dataset. Instead, you have to build your own. Your search engine will run on text documents. So, here\n",
    "we detail the procedure to follow for the data collection. We strongly suggest you work on different modules when implementing the required functions. For example, you may have a ```crawler.py``` module, a ```parser.py``` module, and a ```engine.py``` module: this is a good practice that improves readability in reporting and efficiency in deploying the code. Be careful; you are likely dealing with exceptions and other possible issues! \n",
    "\n",
    "### 1.1. Get the list of master's degree courses\n",
    "\n",
    "We start with the list of courses to include in your corpus of documents. In particular, we focus on web scrapping the [MSc Degrees](https://www.findamasters.com/masters-degrees/msc-degrees/). Next, we want you to **collect the URL** associated with each site in the list from the previously collected list.\n",
    "The list is long and split into many pages. Therefore, we ask you to retrieve only the URLs of the places listed in **the first 400 pages** (each page has 15 courses, so you will end up with 6000 unique master's degree URLs).\n",
    "\n",
    "The output of this step is a `.txt` file whose single line corresponds to the master's URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"urls.txt\",\"w\") # First I create a txt file where I can write the URLs  #  w means writing mode\n",
    "for i in range(1, 401): #from first page to page 400\n",
    "    url = f\"https://www.findamasters.com/masters-degrees/msc-degrees/?PG={i}\" #pages can be scrolled by changing the number after PG\n",
    "    result = requests.get(url) # as we have done in class\n",
    "    soup = BeautifulSoup(result.text, 'html.parser') # to get the html of each page\n",
    "\n",
    "    for link in soup.find_all(class_ = re.compile('courseLink')): #as in class to get each tag of the page which belongs to class courseLink\n",
    "        c = (link.get(\"href\"))  # url of each page in the i-th page\n",
    "        f.write(\"https://www.findamasters.com/\"+c) #writing the rows\n",
    "        f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl master's degree pages\n",
    "\n",
    "Once you get all the URLs in the first 400 pages of the list, you:\n",
    "\n",
    "1. Download the HTML corresponding to each of the collected URLs.\n",
    "2. After you collect a single page, immediately save its `HTML` in a file. In this way, if your program stops for any reason, you will not lose the data collected up to the stopping point.\n",
    "3. Organize the downloaded `HTML` pages into folders. Each folder will contain the `HTML` of the courses on page 1, page 2, ... of the list of master's programs.\n",
    "   \n",
    "__Tip__: Due to the large number of pages you should download, you can use some methods that can help you shorten the time. If you employed a particular process or approach, kindly describe it.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggested by chatgpt.. to not be blocked but I'm blocked :(\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching https://www.findamasters.com//masters-degrees/course/3d-design-for-virtual-environments-msc/?i93d2645c19223: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/accounting-and-finance-msc/?i321d3232c3891: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/accounting-accountability-and-financial-management-msc/?i132d7816c25522: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/accounting-financial-management-and-digital-business-msc/?i345d4286c351: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/addictions-msc/?i132d4318c27100: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/advanced-chemical-engineering-msc/?i321d8433c50447: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/advanced-master-in-financial-markets/?i1298d6514c28542: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/advanced-master-in-innovation-and-strategic-management/?i1298d6514c28544: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/advanced-physiotherapy-practice-msc/?i93d2635c71983: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/agricultural-sciences-msc-agriculture-and-forestry/?i312d6223c45169: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/agricultural-environmental-and-resource-economics-msc-agriculture-and-forestry/?i312d6223c45168: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/air-quality-solutions-msc/?i321d1045c71834: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/analytical-toxicology-msc/?i132d4846c14767: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/applied-computer-science-and-artificial-intelligence-msc/?i285d7565c71206: HTTP Error 403: Forbidden\n",
      "Error fetching https://www.findamasters.com//masters-degrees/course/applied-economics-banking-and-financial-markets-online-msc/?i280d8352c56675: HTTP Error 403: Forbidden\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 2): #scraping only in the first page to see if it works\n",
    "    url = f\"https://www.findamasters.com/masters-degrees/msc-degrees/?PG={i}\" \n",
    "    reqs = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    os.makedirs(\"PAGE\" + str(i)) # Creating a folder, its name is PAGE and the number of the page\n",
    "    os.chdir(\"PAGE\" + str(i)) # Going into the folder\n",
    "    \n",
    "    for link in soup.find_all(class_=re.compile('courseLink')):\n",
    "        a = link.get('href')\n",
    "        url_ = \"https://www.findamasters.com/\" + a\n",
    "        filename = re.sub(r'[^a-zA-Z0-9_.]', '_', str(a)[8:]) + '.html' #to have a right file name \n",
    "        file = open(filename, 'w', encoding=\"UTF-8\")\n",
    "        try:\n",
    "            with urlopen(url_) as webpage:\n",
    "                content = webpage.read().decode()\n",
    "                file.write(content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url_}: {e}\")\n",
    "        \n",
    "        file.close()\n",
    "        time.sleep(2)  # Introduce a delay to avoid rate limiting\n",
    "    os.chdir('..')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
